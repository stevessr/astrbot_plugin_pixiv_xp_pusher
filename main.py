from __future__ import annotations

import asyncio
import os
import random
import re
import sys
from pathlib import Path
from typing import TYPE_CHECKING

from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger

# Ensure project root in path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

import aiohttp
from database import cache_illust, init_db, mark_pushed
from fetcher import ContentFetcher
from filter import ContentFilter
from pixiv_client import PixivClient
from profiler import XPProfiler
from utils import download_image_with_referer, get_pixiv_cat_url

from astrbot.api import AstrBotConfig, logger
from astrbot.api.event import AstrMessageEvent, MessageChain, filter
from astrbot.api.message_components import Image, Plain, Reply
from astrbot.api.star import Context, Star
from astrbot.core.platform.astr_message_event import MessageSesion
from astrbot.core.star.filter.command import GreedyStr
from astrbot.core.utils.io import save_temp_img

if TYPE_CHECKING:
    from astrbot_plugin_matrix_adapter.matrix_adapter import MatrixPlatformAdapter
    from pixiv_client import Illust


PIXIV_ILLUST_ID_RE = re.compile(r"(?:artworks/|#)(\d{5,})")


def _parse_search_tags(raw_tags: str) -> dict:
    cleaned = (raw_tags or "").strip()
    all_tags = [t.strip() for t in cleaned.replace("ï¼Œ", ",").split(",") if t.strip()]
    include_tags = []
    exclude_tags = []
    for tag in all_tags:
        if tag.startswith("-") and len(tag) > 1:
            exclude_tags.append(tag[1:].lower())
        else:
            include_tags.append(tag)
    include_tags_lower = [t.lower() for t in include_tags]
    conflict_tags = [t for t in exclude_tags if t in include_tags_lower]
    if conflict_tags:
        conflict_list = "ã€".join(conflict_tags)
        return {
            "success": False,
            "error_message": f"æ ‡ç­¾å†²çªï¼šä»¥ä¸‹æ ‡ç­¾åŒæ—¶å‡ºç°åœ¨åŒ…å«å’Œæ’é™¤åˆ—è¡¨ä¸­ï¼š{conflict_list}",
            "include_tags": [],
            "exclude_tags": [],
            "display_tags": cleaned,
        }
    if not include_tags:
        return {
            "success": False,
            "error_message": "è¯·è‡³å°‘æä¾›ä¸€ä¸ªåŒ…å«æ ‡ç­¾ï¼ˆä¸ä»¥ - å¼€å¤´çš„æ ‡ç­¾ï¼‰ã€‚",
            "include_tags": [],
            "exclude_tags": [],
            "display_tags": cleaned,
        }
    return {
        "success": True,
        "error_message": "",
        "include_tags": include_tags,
        "exclude_tags": exclude_tags,
        "display_tags": cleaned,
    }


def _has_excluded_tags(illust: Illust, excluded_tags: list[str]) -> bool:
    if not excluded_tags:
        return False
    for tag in illust.tags or []:
        lname = str(tag).lower()
        if any(excluded_tag in lname for excluded_tag in excluded_tags):
            return True
    return False


def _filter_search_illusts(
    illusts: list[Illust],
    excluded_tags: list[str],
    r18_mode: str,
    exclude_ai: bool,
) -> tuple[list[Illust], list[str]]:
    filtered = []
    filtered_out = {"r18": 0, "ai": 0, "exclude": 0}
    for illust in illusts:
        if exclude_ai and getattr(illust, "ai_type", 0) == 2:
            filtered_out["ai"] += 1
            continue
        mode_str = str(r18_mode).lower()
        if mode_str in ("true", "r18_only", "pure"):
            if not getattr(illust, "is_r18", False):
                filtered_out["r18"] += 1
                continue
        elif mode_str in ("safe", "18-", "clean"):
            if getattr(illust, "is_r18", False):
                filtered_out["r18"] += 1
                continue
        if _has_excluded_tags(illust, excluded_tags):
            filtered_out["exclude"] += 1
            continue
        filtered.append(illust)

    messages = []
    total = len(illusts)
    if total > 0 and len(filtered) < total:
        reasons = []
        if filtered_out["r18"] > 0:
            reasons.append("R18")
        if filtered_out["ai"] > 0:
            reasons.append("AI")
        if filtered_out["exclude"] > 0:
            reasons.append("æ’é™¤æ ‡ç­¾")
        if reasons:
            messages.append(
                f"éƒ¨åˆ†ä½œå“å›  {'/'.join(reasons)} è®¾ç½®è¢«è¿‡æ»¤ (æ‰¾åˆ° {total} ä¸ªä½œå“ï¼Œæœ€ç»ˆå‰© {len(filtered)} ä¸ªå¯å‘é€)ã€‚"
            )
    if total > 0 and len(filtered) == 0:
        messages.append("ç­›é€‰åæ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„ä½œå“å¯å‘é€ã€‚")
    return filtered, messages


def _pick_search_image_url(
    illust: Illust, use_pixiv_cat: bool, max_pages: int
) -> str | None:
    if not illust.page_count:
        return None
    limit = max(1, min(max_pages, illust.page_count))
    if use_pixiv_cat:
        return get_pixiv_cat_url(illust.id, 0) if limit > 0 else None
    if illust.image_urls:
        return illust.image_urls[0]
    return None


def _format_search_message(illust: Illust) -> str:
    tags = ", ".join(illust.tags[:20]) if illust.tags else "N/A"
    r18 = "R18" if illust.is_r18 else "SAFE"
    return (
        f"ğŸ¨ {illust.title} (#{illust.id})\n"
        f"ğŸ‘¤ {illust.user_name} ({illust.user_id})\n"
        f"ğŸ”– {tags}\n"
        f"â­ {illust.bookmark_count} | ğŸ‘€ {illust.view_count} | {r18}\n"
        f"ğŸ”— https://www.pixiv.net/artworks/{illust.id}"
    )


def _sample_illusts(illusts: list[Illust], count: int) -> list[Illust]:
    if not illusts:
        return []
    count_to_send = max(1, min(len(illusts), count))
    random.shuffle(illusts)
    return illusts[:count_to_send]


async def retry_async(
    coro_func,
    *args,
    max_retries: int = 3,
    delay: float = 5.0,
    backoff: float = 2.0,
    **kwargs,
):
    """
    é€šç”¨å¼‚æ­¥é‡è¯•å‡½æ•°

    Args:
        coro_func: è¦æ‰§è¡Œçš„å¼‚æ­¥å‡½æ•°
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        delay: åˆå§‹å»¶è¿Ÿç§’æ•°
        backoff: å»¶è¿Ÿå€å¢ç³»æ•°

    Returns:
        å‡½æ•°è¿”å›å€¼ï¼Œæˆ–åœ¨æ‰€æœ‰é‡è¯•å¤±è´¥åè¿”å› None
    """
    current_delay = delay

    for attempt in range(max_retries + 1):
        try:
            return await coro_func(*args, **kwargs)
        except Exception as e:
            if attempt < max_retries:
                logger.warning(
                    f"æ“ä½œå¤±è´¥ (å°è¯• {attempt + 1}/{max_retries + 1}): {e}ï¼Œ{current_delay:.1f}s åé‡è¯•..."
                )
                await asyncio.sleep(current_delay)
                current_delay *= backoff
            else:
                logger.error(f"æ“ä½œæœ€ç»ˆå¤±è´¥ (å·²é‡è¯• {max_retries} æ¬¡): {e}")

    return None


# å…¨å±€è¿è¡Œé”ï¼Œé˜²æ­¢ä»»åŠ¡å¹¶å‘
_task_lock = asyncio.Lock()


async def setup_notifiers(
    config: dict,
    client: PixivClient,
    profiler: XPProfiler,
    sync_client: PixivClient = None,
):
    raise RuntimeError(
        "Non-AstrBot notifiers have been removed; use notifiers_factory."
    )


async def setup_services(config: dict, notifiers_factory=None):
    """åˆå§‹åŒ–å…¨å±€æœåŠ¡ (DB, Client, Profiler, Notifiers)"""
    await init_db()

    # å…¬å…±ç½‘ç»œé…ç½®
    network_cfg = config.get("network", {})
    pixiv_cfg = config.get("pixiv", {})
    proxy_url = network_cfg.get("proxy_url")

    client_kwargs = {
        "requests_per_minute": network_cfg.get("requests_per_minute", 60),
        "random_delay": tuple(network_cfg.get("random_delay", [1.0, 3.0])),
        "max_concurrency": network_cfg.get("max_concurrency", 5),
        "proxy_url": proxy_url,
    }

    # ä¸»å®¢æˆ·ç«¯ (ç”¨äºæœç´¢ã€æ’è¡Œæ¦œç­‰é«˜é£é™©æ“ä½œ)
    main_client = PixivClient(
        refresh_token=pixiv_cfg.get("refresh_token"), **client_kwargs
    )
    await main_client.login()

    # åŒæ­¥å®¢æˆ·ç«¯ (ç”¨äºè·å–æ”¶è—ã€å…³æ³¨åŠ¨æ€ç­‰ä½é£é™©æ“ä½œ)
    sync_token = pixiv_cfg.get("sync_token")
    if sync_token:
        sync_client = PixivClient(refresh_token=sync_token, **client_kwargs)
        await sync_client.login()
        logger.info("âœ… å·²å¯ç”¨åŒæ­¥ä¸“ç”¨ Token (sync_token)")
    else:
        sync_client = main_client  # å›é€€åˆ°ä¸»å®¢æˆ·ç«¯
        logger.info("æœªé…ç½® sync_tokenï¼Œæ”¶è—åŒæ­¥å°†ä½¿ç”¨ä¸» Token")

    # Init Profiler (ä½¿ç”¨ sync_clientï¼Œåªè¯»æ“ä½œ)
    profiler_cfg = config.get("profiler", {})
    profiler = XPProfiler(
        client=sync_client,  # ä½¿ç”¨åŒæ­¥å®¢æˆ·ç«¯è·å–æ”¶è—
        stop_words=profiler_cfg.get("stop_words"),
        discovery_rate=profiler_cfg.get("discovery_rate", 0.1),
        time_decay_days=profiler_cfg.get("time_decay_days", 180),
        ai_config=profiler_cfg.get("ai"),
        saturation_threshold=profiler_cfg.get("saturation_threshold", 0.5),
    )

    # Init Notifiers (ä½¿ç”¨ main_client ç”¨äºä¸‹è½½å›¾ç‰‡ç­‰ï¼Œsync_client ç”¨äº on_action å›è°ƒ)
    if notifiers_factory:
        notifiers = await notifiers_factory(config, main_client, profiler, sync_client)
    else:
        notifiers = await setup_notifiers(config, main_client, profiler, sync_client)

    # è¿”å›åŒå®¢æˆ·ç«¯
    return main_client, sync_client, profiler, notifiers


async def main_task(
    config: dict,
    client: PixivClient,
    profiler: XPProfiler,
    notifiers: list,
    sync_client: PixivClient = None,
):
    """
    æ‰§è¡Œä¸€æ¬¡å®Œæ•´çš„æ¨é€ä»»åŠ¡ (ä¾èµ–å¤–éƒ¨æœåŠ¡)

    Args:
        client: ä¸»å®¢æˆ·ç«¯ (ç”¨äºæœç´¢ã€æ’è¡Œæ¦œã€ä¸‹è½½)
        sync_client: åŒæ­¥å®¢æˆ·ç«¯ (ç”¨äºè·å–å…³æ³¨åŠ¨æ€ï¼Œå¯é€‰)
    """
    # å¦‚æœæœªä¼ å…¥ sync_clientï¼Œä½¿ç”¨ main_client
    if sync_client is None:
        sync_client = client

    if _task_lock.locked():
        logger.info("â³ æ¨é€ä»»åŠ¡æ­£åœ¨è¿è¡Œä¸­ï¼Œæœ¬æ¬¡è§¦å‘å·²è·³è¿‡æˆ–æ’é˜Ÿ")

    async with _task_lock:
        logger.info("=== å¼€å§‹æ¨é€ä»»åŠ¡ ===")

    try:
        # 1. æ„å»º/æ›´æ–° XP ç”»åƒ
        profiler_cfg = config.get("profiler", {})

        await profiler.build_profile(
            user_id=config["pixiv"]["user_id"],
            scan_limit=profiler_cfg.get("scan_limit", 500),
            include_private=profiler_cfg.get("include_private", True),
        )

        top_tags = await profiler.get_top_tags(profiler_cfg.get("top_n", 20))
        logger.info(f"Top XP Tags: {[t[0] for t in top_tags[:10]]}")

        if config.get(
            "test"
        ):  # Test mode skip heavy DB load if possible, but we need it for xp_profile
            pass

        # è·å–å®Œæ•´çš„ XP Profile ç”¨äºåŒ¹é…åº¦è®¡ç®—
        import database as db_module

        xp_profile = await db_module.get_xp_profile()

        # 2. è·å–å†…å®¹
        fetcher_cfg = config.get("fetcher", {})

        # 1.5 è·å–å…³æ³¨åˆ—è¡¨ï¼ˆä½¿ç”¨ sync_clientï¼Œä½é£é™©æ“ä½œï¼‰
        following_ids = set()
        pixiv_uid = config.get("pixiv", {}).get("user_id", 0)
        if pixiv_uid:
            try:
                following_ids = await sync_client.fetch_following(user_id=pixiv_uid)
            except Exception as e:
                logger.warning(f"è·å–å…³æ³¨åˆ—è¡¨å¤±è´¥ï¼š{e}")

        manual_subs = set(fetcher_cfg.get("subscribed_artists") or [])
        all_subs = list(following_ids | manual_subs)
        logger.info(
            f"æœ‰æ•ˆå…³æ³¨ç”»å¸ˆæ•°ï¼š{len(all_subs)} (API è·å–ï¼š{len(following_ids)}, æ‰‹åŠ¨ï¼š{len(manual_subs)})"
        )

        # ContentFetcher: æœç´¢/æ’è¡Œæ¦œç”¨ clientï¼Œè®¢é˜…æ£€æŸ¥ç”¨ sync_client
        fetcher = ContentFetcher(
            client=client,
            sync_client=sync_client,  # æ–°å¢ï¼šåŒæ­¥å®¢æˆ·ç«¯
            bookmark_threshold=fetcher_cfg.get(
                "bookmark_threshold", {"search": 1000, "subscription": 0}
            ),
            date_range_days=fetcher_cfg.get("date_range_days", 7),
            subscribed_artists=list(manual_subs),
            discovery_rate=profiler_cfg.get("discovery_rate", 0.1),
            ranking_config=fetcher_cfg.get("ranking"),
            dynamic_threshold_config=fetcher_cfg.get(
                "dynamic_threshold"
            ),  # åŠ¨æ€é˜ˆå€¼é…ç½®
            search_limit=fetcher_cfg.get("search_limit", 50),  # æœç´¢æ•°é‡é™åˆ¶ (é»˜è®¤ 50)
        )

        # æ‰§è¡Œ Discovery (Search + Ranking + Subs)
        top_tags = await profiler.get_top_tags(
            profiler_cfg.get("top_n", 20)
        )  # Re-get is cheap

        # æ‰§è¡Œ Discovery (Search + Ranking + Subs) -> MAB Scheduled
        top_tags = await profiler.get_top_tags(
            profiler_cfg.get("top_n", 20)
        )  # Re-get is cheap

        all_illusts = await fetcher.fetch_content(
            xp_tags=top_tags, total_limit=fetcher_cfg.get("discovery_limit", 200)
        )
        logger.info(f"å…±è·å– {len(all_illusts)} ä¸ªå€™é€‰ä½œå“")

        # 3. è¿‡æ»¤
        filter_cfg = config.get("filter", {})
        # åˆå§‹åŒ–å¯é€‰çš„ Embedder (AI è¯­ä¹‰åŒ¹é…)
        embedder = None
        ai_cfg = config.get("ai", {})
        embedding_cfg = ai_cfg.get("embedding", {})
        if embedding_cfg.get("enabled", False):
            try:
                from embedder import Embedder

                embedder = Embedder(embedding_cfg)
                if embedder.enabled:
                    logger.info(f"å·²å¯ç”¨ AI è¯­ä¹‰åŒ¹é… (model={embedder.model})")
            except Exception as e:
                logger.warning(f"Embedder åˆå§‹åŒ–å¤±è´¥ï¼š{e}")

        # åˆå§‹åŒ–å¯é€‰çš„ AIScorer (LLM ç²¾æ’)
        ai_scorer = None
        scorer_cfg = ai_cfg.get("scorer", {})
        if scorer_cfg.get("enabled", False):
            try:
                from ai_scorer import AIScorer

                # æ”¯æŒå¤ç”¨ profiler.ai çš„ API é…ç½®
                if scorer_cfg.get("use_profiler_api", True):
                    profiler_ai_cfg = config.get("profiler", {}).get("ai", {})
                    # åˆå¹¶é…ç½®ï¼šscorer ä¼˜å…ˆï¼Œç¼ºå¤±çš„ä» profiler.ai ç»§æ‰¿
                    merged_cfg = {
                        "enabled": scorer_cfg.get("enabled", False),
                        "provider": scorer_cfg.get("provider")
                        or profiler_ai_cfg.get("provider", "openai"),
                        "api_key": scorer_cfg.get("api_key")
                        or profiler_ai_cfg.get("api_key", ""),
                        "base_url": scorer_cfg.get("base_url")
                        or profiler_ai_cfg.get("base_url", ""),
                        "model": scorer_cfg.get("model")
                        or profiler_ai_cfg.get("model", ""),
                        "max_candidates": scorer_cfg.get("max_candidates", 50),
                        "score_weight": scorer_cfg.get("score_weight", 0.3),
                    }
                    ai_scorer = AIScorer(merged_cfg)
                else:
                    ai_scorer = AIScorer(scorer_cfg)

                if ai_scorer.enabled:
                    logger.info(f"å·²å¯ç”¨ AI ç²¾æ’è¯„åˆ† (model={ai_scorer.model})")
            except Exception as e:
                logger.warning(f"AIScorer åˆå§‹åŒ–å¤±è´¥ï¼š{e}")

        content_filter = ContentFilter(
            blacklist_tags=filter_cfg.get("blacklist_tags"),
            daily_limit=filter_cfg.get("daily_limit", 20),
            exclude_ai=filter_cfg.get("exclude_ai", True),
            min_match_score=filter_cfg.get("min_match_score", 0.0),
            match_weight=filter_cfg.get("match_weight", 0.6),
            max_per_artist=filter_cfg.get("max_per_artist", 3),
            subscribed_artists=all_subs,
            artist_boost=filter_cfg.get("artist_boost", 0.3),
            min_create_days=filter_cfg.get("min_create_days", 0),
            r18_mode=filter_cfg.get("r18_mode", False),
            # æ–°å¢ï¼šå€Ÿé‰´ X ç®—æ³•çš„å¢å¼ºé€‰é¡¹
            author_diversity=filter_cfg.get("author_diversity"),
            source_boost=filter_cfg.get("source_boost"),
            embedder=embedder,  # å¯é€‰çš„è¯­ä¹‰åŒ¹é…
            ai_scorer=ai_scorer,  # å¯é€‰çš„ LLM ç²¾æ’
            # å¤šæ ·æ€§å¢å¼º
            shuffle_factor=filter_cfg.get("shuffle_factor", 0.0),
            exploration_ratio=filter_cfg.get("exploration_ratio", 0.0),
        )

        pixiv_uid = config.get("pixiv", {}).get("user_id", 0)
        filtered = await content_filter.filter(
            all_illusts, xp_profile=xp_profile, user_id=pixiv_uid
        )
        logger.info(f"è¿‡æ»¤å {len(filtered)} ä¸ªä½œå“")

        # 4. æ¨é€
        if notifiers and filtered:
            try:
                # ç¼“å­˜ä½œå“ä¿¡æ¯ (åŒ…å«æ¥æºå½’å› )
                for illust in filtered:
                    await cache_illust(
                        illust.id,
                        illust.tags,
                        illust.user_id,
                        illust.user_name,
                        source=illust.source,
                    )

                all_sent_ids = set()
                for notifier in notifiers:
                    try:
                        sent_ids = await notifier.send(filtered)
                        all_sent_ids.update(sent_ids)
                    except Exception as e:
                        logger.error(f"æ¨é€å™¨ {type(notifier).__name__} å‘é€å¤±è´¥ï¼š{e}")

                if all_sent_ids:
                    # è®°å½•æ¨é€å†å²
                    filtered_map = {ill.id: ill for ill in filtered}
                    for pid in all_sent_ids:
                        if pid in filtered_map:
                            illust = filtered_map[pid]
                            source = getattr(illust, "source", "unknown")
                            await mark_pushed(pid, source)

                            # æ›´æ–° MAB ç­–ç•¥ç»Ÿè®¡ (Total Count)
                            if source in [
                                "xp_search",
                                "subscription",
                                "ranking",
                                "related",
                                "engagement_artists",
                            ]:
                                await db_module.update_strategy_stats(
                                    source, is_success=False
                                )

                    # å°†æ¶ˆæ¯ ID å†™å…¥æ•°æ®åº“ç¼“å­˜ï¼ˆç”¨äºè¿é”æ¨é€å¼•ç”¨ï¼‰
                    for notifier in notifiers:
                        if hasattr(notifier, "_message_illust_map"):
                            for (
                                msg_id,
                                illust_id,
                            ) in notifier._message_illust_map.items():
                                if illust_id in all_sent_ids:
                                    await db_module.set_chain_meta(
                                        illust_id, chain_depth=0, chain_msg_id=msg_id
                                    )

                    logger.info(
                        f"æ¨é€å®Œæˆï¼š{len(all_sent_ids)}/{len(filtered)} ä¸ªä½œå“æˆåŠŸ"
                    )
                else:
                    logger.error("æ²¡æœ‰ä»»ä½•ä½œå“è¢«æˆåŠŸæ¨é€")

                # 5. AI é”™è¯¯æŠ¥è­¦
                ai_errors = profiler.ai_processor.occurred_errors
                if ai_errors:
                    err_count = len(ai_errors)
                    err_id = ai_errors[0]
                    msg = f"âš ï¸ è­¦å‘Šï¼šæœ¬æ¬¡ä»»åŠ¡æœ‰ {err_count} æ‰¹ Tag AI ä¼˜åŒ–å¤±è´¥ã€‚\nå·²è‡ªåŠ¨è®°å½•å¹¶é™çº§å¤„ç†ã€‚"
                    buttons = [("ğŸ”„ é‡è¯•ä¿®å¤", f"retry_ai:{err_id}")]
                    logger.warning(f"AI ä¼˜åŒ–å¤±è´¥ {err_count} æ¬¡ï¼Œå‘é€è­¦å‘Š")

                    for notifier in notifiers:
                        if hasattr(notifier, "send_text"):
                            try:
                                await notifier.send_text(msg, buttons)
                            except Exception as e:
                                logger.debug(f"AI é”™è¯¯æç¤ºå‘é€å¤±è´¥ï¼š{e}")
            except Exception as e:
                logger.error(f"æ¨é€è¿‡ç¨‹å‡ºé”™ï¼š{e}")
        elif not filtered:
            logger.info("æ— æ–°ä½œå“å¯æ¨é€")
        else:
            logger.warning("æœªé…ç½®æ¨é€å™¨")

    except Exception as e:
        logger.error(f"ä»»åŠ¡æ‰§è¡Œå‡ºé”™ï¼š{e}", exc_info=True)

    logger.info("=== æ¨é€ä»»åŠ¡ç»“æŸ ===")


async def run_once(config: dict, notifiers_factory=None):
    """ç«‹å³æ‰§è¡Œä¸€æ¬¡"""
    main_client, sync_client, profiler, notifiers = await setup_services(
        config, notifiers_factory=notifiers_factory
    )

    # Run-once æ˜¯ Fire-and-Forget è¡Œä¸º

    try:
        await main_task(config, main_client, profiler, notifiers, sync_client)
    finally:
        await main_client.close()
        # å¦‚æœ sync_client æ˜¯ç‹¬ç«‹å®ä¾‹ï¼Œä¹Ÿéœ€è¦å…³é—­
        if sync_client is not main_client:
            await sync_client.close()
        for n in notifiers or []:
            if hasattr(n, "close"):
                try:
                    await n.close()
                except Exception as e:
                    logger.debug(f"å…³é—­æ¨é€å™¨å¤±è´¥ï¼š{e}")


async def daily_report_task(config: dict, notifiers: list, profiler=None):
    """æ¯æ—¥ç»´æŠ¤ä»»åŠ¡ï¼šç”Ÿæˆæ—¥æŠ¥ + æ•°æ®æ¸…ç† + AI æ ‡ç­¾åˆ·æ–°

    è®¾è®¡åŸåˆ™ï¼š
    - æ¯ä¸ªæ­¥éª¤ç‹¬ç«‹ try/exceptï¼Œå³ä½¿æŸä¸€æ­¥å¤±è´¥ï¼Œå…¶ä»–æ­¥éª¤ä»å¯ç»§ç»­
    - ç½‘ç»œç›¸å…³æ“ä½œï¼ˆAIã€å‘é€ï¼‰ä½¿ç”¨ retry_async è‡ªåŠ¨é‡è¯•
    """
    logger.info("ğŸ“Š å¼€å§‹æ‰§è¡Œæ¯æ—¥ç»´æŠ¤ä»»åŠ¡...")

    maintenance_summary = []
    lines = ["ğŸ“Š **æ¯æ—¥ XP æ—¥æŠ¥**\n"]

    # ========== 1. ç”Ÿæˆæ—¥æŠ¥ (Top Tags + MAB Stats) ==========
    try:
        from database import get_all_strategy_stats, get_top_xp_tags

        top_tags = await get_top_xp_tags(10)
        stats = await get_all_strategy_stats()

        if top_tags:
            lines.append("ğŸ¯ **Top 10 XP æ ‡ç­¾**")
            for i, (tag, weight) in enumerate(top_tags[:10], 1):
                lines.append(f"  {i}. `{tag}` ({weight:.1f})")
            lines.append("")

        if stats:
            lines.append("ğŸ“ˆ **MAB ç­–ç•¥è¡¨ç°**")
            strategy_names = {
                "search": "XP æœç´¢",
                "xp_search": "XP æœç´¢",
                "subscription": "è®¢é˜…",
                "ranking": "æ’è¡Œæ¦œ",
            }
            for strategy, data in stats.items():
                name = strategy_names.get(strategy, strategy)
                rate_pct = data["rate"] * 100
                lines.append(
                    f"  â€¢ {name}: {data['success']}/{data['total']} ({rate_pct:.1f}%)"
                )
    except Exception as e:
        logger.error(f"ç”Ÿæˆæ—¥æŠ¥ç»Ÿè®¡å¤±è´¥ï¼š{e}")
        maintenance_summary.append(f"âš ï¸ æ—¥æŠ¥ç»Ÿè®¡å¤±è´¥ï¼š{e}")

    # ========== 2. åŒæ­¥å±è”½æ ‡ç­¾åˆ° XP ç”»åƒ ==========
    try:
        from database import sync_blocked_tags_to_xp

        blocked_removed = await sync_blocked_tags_to_xp()
        if blocked_removed > 0:
            maintenance_summary.append(
                f"ğŸš« ä»ç”»åƒä¸­ç§»é™¤ {blocked_removed} ä¸ªå·²å±è”½æ ‡ç­¾"
            )
            logger.info(f"å·²ä» XP ç”»åƒä¸­ç§»é™¤ {blocked_removed} ä¸ªå±è”½æ ‡ç­¾")
    except Exception as e:
        logger.error(f"åŒæ­¥å±è”½æ ‡ç­¾å¤±è´¥ï¼š{e}")
        maintenance_summary.append(f"âš ï¸ åŒæ­¥å±è”½æ ‡ç­¾å¤±è´¥ï¼š{e}")

    # ========== 3. AI æ ‡ç­¾å¢é‡å¤„ç† (å¸¦é‡è¯•) ==========
    if profiler and hasattr(profiler, "ai_processor") and profiler.ai_processor.enabled:
        try:
            from database import get_uncached_tags

            uncached_tags = await get_uncached_tags(limit=200)
            if uncached_tags:
                logger.info(f"å‘ç° {len(uncached_tags)} ä¸ªæœªå¤„ç†æ ‡ç­¾ï¼Œå¯åŠ¨ AI æ¸…æ´—...")

                async def _ai_process():
                    return await profiler.ai_processor.process_tags(uncached_tags)

                result = await retry_async(_ai_process, max_retries=3, delay=10.0)
                if result:
                    valid_tags, mapping = result
                    maintenance_summary.append(
                        f"ğŸ¤– AI æ¸…æ´— {len(uncached_tags)} ä¸ªæ ‡ç­¾ â†’ {len(valid_tags)} ä¸ªæœ‰æ•ˆ"
                    )
                    logger.info(
                        f"AI æ¸…æ´—å®Œæˆï¼š{len(valid_tags)}/{len(uncached_tags)} æœ‰æ•ˆ"
                    )
                else:
                    maintenance_summary.append("âš ï¸ AI æ¸…æ´—å¤±è´¥ (å·²é‡è¯•)")
        except Exception as e:
            logger.error(f"AI æ¸…æ´—å¤±è´¥ï¼š{e}")
            maintenance_summary.append(f"âš ï¸ AI æ¸…æ´—å¤±è´¥ï¼š{e}")

    # ========== 4. æ¸…ç†æ—§æ¨é€å†å² ==========
    try:
        from database import cleanup_old_sent_history

        old_removed = await cleanup_old_sent_history(days=30)
        if old_removed > 0:
            maintenance_summary.append(f"ğŸ—‘ï¸ æ¸…ç† {old_removed} æ¡è¿‡æœŸæ¨é€è®°å½•")
            logger.info(f"å·²æ¸…ç† {old_removed} æ¡ 30 å¤©å‰çš„æ¨é€å†å²")
    except Exception as e:
        logger.error(f"æ¸…ç†æ¨é€å†å²å¤±è´¥ï¼š{e}")
        maintenance_summary.append(f"âš ï¸ æ¸…ç†æ¨é€å†å²å¤±è´¥ï¼š{e}")

    # ========== 5. æ¸…ç†æ—§ä½œå“ç¼“å­˜ ==========
    try:
        from database import cleanup_old_illust_cache

        cache_removed = await cleanup_old_illust_cache(days=60)
        if cache_removed > 0:
            maintenance_summary.append(f"ğŸ—‘ï¸ æ¸…ç† {cache_removed} æ¡è¿‡æœŸä½œå“ç¼“å­˜")
            logger.info(f"å·²æ¸…ç† {cache_removed} æ¡ 60 å¤©å‰çš„ä½œå“ç¼“å­˜")
    except Exception as e:
        logger.error(f"æ¸…ç†ä½œå“ç¼“å­˜å¤±è´¥ï¼š{e}")
        maintenance_summary.append(f"âš ï¸ æ¸…ç†ä½œå“ç¼“å­˜å¤±è´¥ï¼š{e}")

    # ========== 6. æ·»åŠ ç»´æŠ¤æ‘˜è¦åˆ°æ—¥æŠ¥ ==========
    if maintenance_summary:
        lines.append("")
        lines.append("ğŸ› ï¸ **ç»´æŠ¤è®°å½•**")
        for item in maintenance_summary:
            lines.append(f"  {item}")

    report_msg = "\n".join(lines)

    # ========== 7. å‘é€æ—¥æŠ¥ (å¸¦é‡è¯•) ==========
    async def _send_report():
        for n in notifiers:
            if hasattr(n, "send_text"):
                await n.send_text(report_msg)
                return True
        return False

    result = await retry_async(_send_report, max_retries=5, delay=30.0, backoff=2.0)
    if not result:
        logger.error("å‘é€æ—¥æŠ¥æœ€ç»ˆå¤±è´¥")

    logger.info("âœ… æ¯æ—¥ç»´æŠ¤ä»»åŠ¡å®Œæˆ")


async def run_scheduler(
    config: dict, run_immediately: bool = False, notifiers_factory=None
):
    """å¯åŠ¨è°ƒåº¦å™¨ (Daemon Mode)"""
    main_client, sync_client, profiler, notifiers = await setup_services(
        config, notifiers_factory=notifiers_factory
    )

    if run_immediately:
        logger.info("ğŸš€ æ­£åœ¨ç«‹å³æ‰§è¡Œé¦–æ¬¡ä»»åŠ¡...")
        asyncio.create_task(
            main_task(config, main_client, profiler, notifiers, sync_client)
        )

    scheduler = AsyncIOScheduler()
    scheduler_cfg = config.get("scheduler", {})
    coalesce = scheduler_cfg.get("coalesce", True)

    # è·å–è°ƒåº¦é…ç½® (ä¼˜å…ˆè¯»å–æ•°æ®åº“)
    from database import get_state

    db_cron = await get_state("schedule_cron")
    config_cron = config.get("scheduler", {}).get("cron", "0 20 * * *")

    schedule_str = db_cron if db_cron else config_cron

    # å°† scheduler æ³¨å…¥åˆ° config ä¸­ä»¥ä¾¿ callback è®¿é—®
    config["scheduler"] = scheduler

    # æ”¯æŒå¤šä¸ªæ—¶é—´ç‚¹
    # é€»è¾‘ä¼˜åŒ–ï¼š
    # 1. å…ˆå°è¯•å°†æ•´ä¸ªå­—ç¬¦ä¸²ä½œä¸ºä¸€ä¸ª Cronï¼Œå¦‚æœæˆåŠŸåˆ™è®¤ä¸ºæ˜¯ä¸€ä¸ªä»»åŠ¡ (è§£å†³ "0 12,21 * * *" è¢«è¯¯æ‹†çš„é—®é¢˜)
    # 2. å¦‚æœå¤±è´¥ï¼Œå†å°è¯•ç”¨é€—å·åˆ†å‰² (å…¼å®¹æ—§çš„å¤šä»»åŠ¡å†™æ³• "0 12 * * *, 0 21 * * *")

    cron_list = []

    # å°è¯•è§£ææ•´ä½“
    try:
        CronTrigger.from_crontab(schedule_str.strip())
        cron_list = [schedule_str.strip()]
        logger.info(f"è¯†åˆ«ä¸ºå•ä¸€å®šæ—¶ä»»åŠ¡ï¼š{schedule_str}")
    except ValueError:
        # æ•´ä½“è§£æå¤±è´¥ï¼Œå°è¯•åˆ†å‰²
        potential_crons = [c.strip() for c in schedule_str.split(",") if c.strip()]
        valid_crons = []
        for c in potential_crons:
            try:
                CronTrigger.from_crontab(c)
                valid_crons.append(c)
            except ValueError:
                logger.warning(f"å¿½ç•¥æ— æ•ˆçš„ Cron è¡¨è¾¾å¼ç‰‡æ®µï¼š{c}")

        if valid_crons:
            cron_list = valid_crons
            logger.info(f"è¯†åˆ«ä¸º {len(cron_list)} ä¸ªç‹¬ç«‹å®šæ—¶ä»»åŠ¡")
        else:
            # å¦‚æœåˆ†å‰²ä¹Ÿå…¨é”™ï¼Œé‚£å¯èƒ½å°±æ˜¯æ•´ä½“å†™é”™äº†ï¼Œä¿ç•™æ•´ä½“è®©åé¢æŠ¥é”™
            cron_list = [schedule_str]

    for i, cron_expr in enumerate(cron_list):
        try:
            scheduler.add_job(
                main_task,
                CronTrigger.from_crontab(cron_expr),
                args=[config, main_client, profiler, notifiers, sync_client],
                id=f"push_job_{i}",
                coalesce=coalesce,
                misfire_grace_time=3600,
            )
            logger.info(f"å·²æ·»åŠ å®šæ—¶ä»»åŠ¡ #{i + 1}: {cron_expr}")
        except Exception as e:
            logger.error(f"æ·»åŠ å®šæ—¶ä»»åŠ¡å¤±è´¥ ({cron_expr}): {e}")

    # æ¯æ—¥ç»´æŠ¤ä»»åŠ¡ (æ—¥æŠ¥ + æ¸…ç†)
    daily_cron = scheduler_cfg.get("daily_report_cron", "0 0 * * *")  # é»˜è®¤æ¯å¤© 00:00
    try:
        scheduler.add_job(
            daily_report_task,
            CronTrigger.from_crontab(daily_cron),
            args=[config, notifiers, profiler],  # ä¼ å…¥ profiler ä»¥æ”¯æŒ AI æ¸…æ´—
            id="daily_report_job",
            coalesce=True,
            misfire_grace_time=3600,
        )
        logger.info(f"å·²æ·»åŠ æ¯æ—¥ç»´æŠ¤ä»»åŠ¡ï¼š{daily_cron}")
    except Exception as e:
        logger.error(f"æ·»åŠ æ¯æ—¥ç»´æŠ¤ä»»åŠ¡å¤±è´¥ï¼š{e}")

    scheduler.start()
    logger.info(f"è°ƒåº¦å™¨å·²å¯åŠ¨ï¼Œå…± {len(cron_list)} ä¸ªæ¨é€ä»»åŠ¡ + 1 ä¸ªæ¯æ—¥ç»´æŠ¤ä»»åŠ¡")

    try:
        stop_event = asyncio.Event()
        await stop_event.wait()
    except (KeyboardInterrupt, SystemExit, asyncio.CancelledError):
        scheduler.shutdown()
        raise
    finally:
        await main_client.close()
        # å¦‚æœ sync_client æ˜¯ç‹¬ç«‹å®ä¾‹ï¼Œä¹Ÿéœ€è¦å…³é—­
        if sync_client is not main_client:
            await sync_client.close()
        for n in notifiers or []:
            if hasattr(n, "close"):
                try:
                    await n.close()
                except Exception as e:
                    logger.debug(f"å…³é—­æ¨é€å™¨å¤±è´¥ï¼š{e}")


def _apply_test_overrides(config: dict) -> None:
    config.setdefault("profiler", {})["scan_limit"] = 10
    config["profiler"]["discovery_rate"] = 0
    config.setdefault("fetcher", {})["bookmark_threshold"] = {
        "search": 0,
        "subscription": 0,
    }
    config.setdefault("fetcher", {})["discovery_limit"] = 1
    config["fetcher"]["ranking"] = {"modes": ["day"], "limit": 1}
    config["test"] = True


def _get_list(cfg: dict, key: str, default: list):
    value = cfg.get(key, default)
    if value is None:
        return list(default)
    if isinstance(value, list):
        return value
    return [value]


def _build_config_from_astrbot(plugin_cfg: AstrBotConfig) -> dict:
    """Build Pixiv-XP-Pusher config from AstrBot plugin config."""
    pixiv_cfg = plugin_cfg.get("pixiv", {}) or {}
    profiler_cfg = plugin_cfg.get("profiler", {}) or {}
    profiler_ai_cfg = profiler_cfg.get("ai", {}) or {}
    ai_cfg = plugin_cfg.get("ai", {}) or {}
    scheduler_cfg = plugin_cfg.get("scheduler", {}) or {}
    filter_cfg = plugin_cfg.get("filter", {}) or {}
    fetcher_cfg = plugin_cfg.get("fetcher", {}) or {}
    network_cfg = plugin_cfg.get("network", {}) or {}

    config = {
        "pixiv": {
            "user_id": pixiv_cfg.get("user_id", 0),
            "refresh_token": pixiv_cfg.get("refresh_token", ""),
            "sync_token": pixiv_cfg.get("sync_token", ""),
        },
        "strategies": _get_list(
            plugin_cfg,
            "strategies",
            ["xp_search", "related", "ranking", "subscription"],
        ),
        "profiler": {
            "ai": {
                "enabled": profiler_ai_cfg.get("enabled", False),
                "provider": profiler_ai_cfg.get("provider", "openai"),
                "api_key": profiler_ai_cfg.get("api_key", ""),
                "base_url": profiler_ai_cfg.get("base_url", ""),
                "model": profiler_ai_cfg.get("model", ""),
                "concurrency": profiler_ai_cfg.get("concurrency", 10),
                "batch_size": profiler_ai_cfg.get("batch_size", 200),
                "filter_meaningless": profiler_ai_cfg.get("filter_meaningless", True),
                "merge_synonyms": profiler_ai_cfg.get("merge_synonyms", True),
            },
            "scan_limit": profiler_cfg.get("scan_limit", 1000),
            "discovery_rate": profiler_cfg.get("discovery_rate", 0.1),
            "time_decay_days": profiler_cfg.get("time_decay_days", 180),
            "saturation_threshold": profiler_cfg.get("saturation_threshold", 0.5),
            "top_n": profiler_cfg.get("top_n", 20),
            "include_private": profiler_cfg.get("include_private", True),
            "stop_words": _get_list(
                profiler_cfg,
                "stop_words",
                ["original", "manga", "pixiv", "illustration"],
            ),
        },
        "ai": {
            "embedding": ai_cfg.get("embedding", {}),
            "scorer": ai_cfg.get("scorer", {}),
        },
        "scheduler": {
            "cron": scheduler_cfg.get("cron", "0 12 * * *"),
            "coalesce": scheduler_cfg.get("coalesce", True),
            "daily_report_cron": scheduler_cfg.get("daily_report_cron", "0 0 * * *"),
        },
        "filter": {
            "daily_limit": filter_cfg.get("daily_limit", 20),
            "exclude_ai": filter_cfg.get("exclude_ai", True),
            "max_per_artist": filter_cfg.get("max_per_artist", 3),
            "artist_boost": filter_cfg.get("artist_boost", 0.3),
            "min_create_days": filter_cfg.get("min_create_days", 0),
            "r18_mode": filter_cfg.get("r18_mode", "mixed"),
            "shuffle_factor": filter_cfg.get("shuffle_factor", 0.0),
            "exploration_ratio": filter_cfg.get("exploration_ratio", 0.0),
            "blacklist_tags": _get_list(filter_cfg, "blacklist_tags", []),
            "min_match_score": filter_cfg.get("min_match_score", 0.0),
            "match_weight": filter_cfg.get("match_weight", 0.6),
            "author_diversity": filter_cfg.get("author_diversity", {}),
            "source_boost": filter_cfg.get("source_boost", {}),
        },
        "fetcher": {
            "bookmark_threshold": {
                "search": fetcher_cfg.get("bookmark_threshold", {}).get("search", 1000),
                "subscription": fetcher_cfg.get("bookmark_threshold", {}).get(
                    "subscription", 0
                ),
            },
            "subscribed_artists": _get_list(fetcher_cfg, "subscribed_artists", []),
            "date_range_days": fetcher_cfg.get("date_range_days", 7),
            "dynamic_threshold": fetcher_cfg.get("dynamic_threshold", {}),
            "search_limit": fetcher_cfg.get("search_limit", 50),
            "ranking": fetcher_cfg.get(
                "ranking",
                {"enabled": True, "modes": ["day", "week", "month"], "limit": 100},
            ),
            "mab_limits": fetcher_cfg.get(
                "mab_limits", {"min_quota": 0.2, "max_quota": 0.6}
            ),
        },
        "network": {
            "requests_per_minute": network_cfg.get("requests_per_minute", 60),
            "random_delay": network_cfg.get("random_delay", [1.0, 3.0]),
            "max_concurrency": network_cfg.get("max_concurrency", 5),
            "proxy_url": network_cfg.get("proxy_url", ""),
        },
        "notifier": {
            "max_pages": plugin_cfg.get("max_pages", 10),
            "multi_page_mode": plugin_cfg.get("multi_page_mode", "cover_link"),
        },
    }

    return config


def _build_push_sessions(plugin_cfg: AstrBotConfig) -> list[str]:
    return _get_list(plugin_cfg, "push_sessions", [])


class AstrBotNotifier:
    """Send Pixiv messages through AstrBot's builtin proactive channels."""

    def __init__(
        self,
        context: Context,
        sessions: list[str],
        max_pages: int = 10,
        multi_page_mode: str = "cover_link",
        use_pixiv_cat: bool = True,
        proxy_url: str | None = None,
    ) -> None:
        self.context = context
        self.sessions = sessions
        self.max_pages = max_pages
        self.multi_page_mode = multi_page_mode
        self.use_pixiv_cat = use_pixiv_cat
        self.proxy_url = proxy_url
        self._session: aiohttp.ClientSession | None = None

    def _get_platform_for_session(self, session_str: str):
        try:
            session = MessageSesion.from_str(session_str)
        except Exception:
            return None, None

        for platform in self.context.platform_manager.get_insts():
            try:
                if platform.meta().id == session.platform_id:
                    return platform, session
            except Exception:
                continue
        return None, session

    def _resolve_matrix_adapter(self, session_str: str):
        platform, session = self._get_platform_for_session(session_str)
        if session is None:
            return None, None
        if platform is None:
            return None, session
        try:
            from astrbot_plugin_matrix_adapter.matrix_adapter import (
                MatrixPlatformAdapter,
            )

            if isinstance(platform, MatrixPlatformAdapter):
                return platform, session
        except Exception:
            return None, session
        return None, session

    def _pick_image_urls(self, illust: Illust) -> list[str]:
        if not illust.page_count:
            return []
        limit = max(1, min(self.max_pages, illust.page_count))
        if self.use_pixiv_cat:
            return [get_pixiv_cat_url(illust.id, i) for i in range(limit)]
        if illust.image_urls:
            return illust.image_urls[:limit]
        return []

    async def _get_session(self) -> aiohttp.ClientSession:
        if self._session is None or self._session.closed:
            self._session = aiohttp.ClientSession()
        return self._session

    async def _download_to_file(self, url: str) -> str | None:
        try:
            session = await self._get_session()
            data = await download_image_with_referer(session, url, proxy=self.proxy_url)
            return save_temp_img(data)
        except Exception as e:
            logger.warning(
                "ä¸‹è½½å›¾ç‰‡å¤±è´¥ï¼šurl=%s proxy=%s err=%s",
                url,
                self.proxy_url,
                e,
                exc_info=True,
            )
            return None

    async def _send_text_and_get_reply_id(
        self,
        adapter: MatrixPlatformAdapter,
        session_id: str,
        text: str,
    ) -> str | None:
        try:
            from astrbot_plugin_matrix_adapter.sender.handlers.common import (
                send_content,
            )
            from astrbot_plugin_matrix_adapter.utils.markdown_utils import (
                markdown_to_html,
            )
        except Exception:
            return None

        is_encrypted = False
        if getattr(adapter, "e2ee_manager", None):
            try:
                is_encrypted = await adapter.client.is_room_encrypted(session_id)
            except Exception as e:
                logger.debug(f"æ£€æŸ¥ Matrix æˆ¿é—´åŠ å¯†çŠ¶æ€å¤±è´¥ï¼š{e}")

        msg_type = "m.notice" if adapter._matrix_config.use_notice else "m.text"
        content = {"msgtype": msg_type, "body": text}
        try:
            content["format"] = "org.matrix.custom.html"
            content["formatted_body"] = markdown_to_html(text)
        except Exception:
            pass

        resp = await send_content(
            adapter.client,
            content,
            session_id,
            reply_to=None,
            thread_root=None,
            use_thread=False,
            is_encrypted_room=is_encrypted,
            e2ee_manager=adapter.e2ee_manager,
        )
        if not isinstance(resp, dict):
            return None
        return resp.get("event_id")

    def format_message(self, illust: Illust) -> str:
        tags = ", ".join(illust.tags[:20]) if illust.tags else "N/A"
        r18 = "R18" if illust.is_r18 else "SAFE"
        return (
            f"ğŸ¨ {illust.title} (#{illust.id})\n"
            f"ğŸ‘¤ {illust.user_name} ({illust.user_id})\n"
            f"ğŸ”– {tags}\n"
            f"â­ {illust.bookmark_count} | ğŸ‘€ {illust.view_count} | {r18}\n"
            f"ğŸ”— https://www.pixiv.net/artworks/{illust.id}"
        )

    def handle_feedback(self, illust_id: int, action: str) -> bool:
        return False

    async def _send_chain(self, chain: MessageChain) -> None:
        for session in self.sessions:
            await self.context.send_message(session, chain)

    async def send(self, illusts: list[Illust]) -> list[int]:
        if not illusts or not self.sessions:
            return []

        success_ids = []
        for illust in illusts:
            if not illust.title or not illust.user_name:
                logger.warning(
                    "è·³è¿‡å…ƒæ•°æ®ä¸å®Œæ•´çš„ä½œå“ï¼šid=%s title=%s user=%s",
                    illust.id,
                    illust.title,
                    illust.user_name,
                )
                continue
            image_urls = self._pick_image_urls(illust)
            urls = (
                image_urls
                if self.multi_page_mode == "multi_image"
                else [image_urls[0]]
                if image_urls
                else []
            )
            if not urls:
                logger.warning("è·³è¿‡æ— å¯ä¸‹è½½å›¾ç‰‡çš„ä½œå“ï¼šid=%s", illust.id)
                continue
            downloaded_paths = []
            for url in urls:
                path = await self._download_to_file(url)
                if path:
                    downloaded_paths.append(path)
            if not downloaded_paths:
                logger.warning("è·³è¿‡ä¸‹è½½å¤±è´¥çš„ä½œå“ï¼šid=%s", illust.id)
                continue
            for session in self.sessions:
                reply_id = None
                adapter, parsed = self._resolve_matrix_adapter(session)
                if (
                    adapter is not None
                    and parsed is not None
                    and getattr(adapter._matrix_config, "enable_threading", False)
                ):
                    reply_id = await self._send_text_and_get_reply_id(
                        adapter, parsed.session_id, self.format_message(illust)
                    )
                else:
                    text_chain = MessageChain()
                    text_chain.message(self.format_message(illust))
                    await self.context.send_message(session, text_chain)

                image_chain = MessageChain()
                if reply_id:
                    image_chain.chain.append(Reply(id=reply_id))
                for path in downloaded_paths:
                    image_chain.file_image(path)
                if image_chain.chain:
                    await self.context.send_message(session, image_chain)
            success_ids.append(illust.id)
        return success_ids

    async def send_text(
        self, text: str, buttons: list[tuple[str, str]] | None = None
    ) -> bool:
        if not self.sessions:
            return False
        chain = MessageChain()
        chain.message(text)
        await self._send_chain(chain)
        return True

    async def push_illusts(
        self,
        illusts: list[Illust],
        message_prefix: str = "",
        reply_to_message_id: int | None = None,
    ) -> dict[int, int | None]:
        sent_map: dict[int, int | None] = {}
        if not illusts:
            return sent_map
        for illust in illusts:
            if not illust.title or not illust.user_name:
                logger.warning(
                    "è·³è¿‡å…ƒæ•°æ®ä¸å®Œæ•´çš„ä½œå“ï¼šid=%s title=%s user=%s",
                    illust.id,
                    illust.title,
                    illust.user_name,
                )
                continue
            image_urls = self._pick_image_urls(illust)
            if not image_urls:
                logger.warning("è·³è¿‡æ— å¯ä¸‹è½½å›¾ç‰‡çš„ä½œå“ï¼šid=%s", illust.id)
                continue
            path = await self._download_to_file(image_urls[0])
            if not path:
                logger.warning("è·³è¿‡ä¸‹è½½å¤±è´¥çš„ä½œå“ï¼šid=%s", illust.id)
                continue
            text = (
                f"{message_prefix}\n{self.format_message(illust)}"
                if message_prefix
                else self.format_message(illust)
            )
            for session in self.sessions:
                reply_id = None
                adapter, parsed = self._resolve_matrix_adapter(session)
                if (
                    adapter is not None
                    and parsed is not None
                    and getattr(adapter._matrix_config, "enable_threading", False)
                ):
                    reply_id = await self._send_text_and_get_reply_id(
                        adapter, parsed.session_id, text
                    )
                else:
                    text_chain = MessageChain()
                    text_chain.message(text)
                    await self.context.send_message(session, text_chain)

                image_chain = MessageChain()
                if reply_id:
                    image_chain.chain.append(Reply(id=reply_id))
                image_chain.file_image(path)
                if image_chain.chain:
                    await self.context.send_message(session, image_chain)
            sent_map[illust.id] = None
        return sent_map

    async def close(self) -> None:
        if self._session and not self._session.closed:
            await self._session.close()


if Star is not None:

    class PixivXPPusherPlugin(Star):
        """Pixiv XP Pusher plugin wrapper for AstrBot."""

        def __init__(self, context: Context, config: AstrBotConfig) -> None:
            super().__init__(context)
            self.context = context
            self.plugin_config = config
            self.plugin_dir = Path(__file__).parent
            self._scheduler_task: asyncio.Task | None = None
            self._run_once_lock = asyncio.Lock()
            self._last_error: str | None = None

            self._auto_start = bool(self.plugin_config.get("auto_start", True))
            self._run_immediately = bool(
                self.plugin_config.get("run_immediately", False)
            )
            self._test_mode = bool(self.plugin_config.get("test_mode", False))

        def _extract_pixiv_illust_id(self, text: str) -> int | None:
            if not text:
                return None
            match = PIXIV_ILLUST_ID_RE.search(text)
            if not match:
                return None
            try:
                return int(match.group(1))
            except Exception:
                return None

        def _strip_html(self, text: str) -> str:
            return re.sub(r"<[^>]+>", " ", text or "")

        async def _resolve_pixiv_illust_id_from_matrix_event(
            self,
            client,
            room_id: str,
            event_data: dict,
            depth: int = 0,
        ) -> int | None:
            if not isinstance(event_data, dict) or depth > 2:
                return None

            content = event_data.get("content", {}) or {}
            text = content.get("body", "") or ""
            illust_id = self._extract_pixiv_illust_id(text)
            if illust_id:
                return illust_id

            formatted = content.get("formatted_body", "")
            if formatted:
                illust_id = self._extract_pixiv_illust_id(self._strip_html(formatted))
                if illust_id:
                    return illust_id

            relates_to = content.get("m.relates_to", {}) or {}
            in_reply_to = relates_to.get("m.in_reply_to", {}).get("event_id")
            if not in_reply_to or in_reply_to == event_data.get("event_id"):
                return None

            try:
                parent_event = await client.get_event(room_id, in_reply_to)
            except Exception as e:
                logger.debug(f"æ‹‰å– Matrix å›å¤æºäº‹ä»¶å¤±è´¥ï¼š{e}")
                return None

            return await self._resolve_pixiv_illust_id_from_matrix_event(
                client, room_id, parent_event, depth + 1
            )

        async def _add_pixiv_bookmark_from_reaction(self, illust_id: int) -> bool:
            config = self._load_runtime_config()
            if not config:
                return False

            pixiv_cfg = config.get("pixiv", {})
            token = pixiv_cfg.get("sync_token") or pixiv_cfg.get("refresh_token")
            if not token:
                logger.warning("æœªé…ç½® Pixiv Tokenï¼Œæ— æ³•é€šè¿‡è¡¨æƒ…æ·»åŠ æ”¶è—ã€‚")
                return False

            network_cfg = config.get("network", {})
            client = PixivClient(
                refresh_token=token,
                requests_per_minute=network_cfg.get("requests_per_minute", 60),
                random_delay=tuple(network_cfg.get("random_delay", [1.0, 3.0])),
                max_concurrency=network_cfg.get("max_concurrency", 5),
                proxy_url=network_cfg.get("proxy_url"),
            )
            try:
                logged_in = await client.login()
                if not logged_in:
                    return False
                return await client.add_bookmark(illust_id)
            finally:
                await client.close()

        async def initialize(self):
            if self._auto_start:
                started, message = await self._start_scheduler()
                if not started:
                    logger.error(f"AstrBot: è‡ªåŠ¨å¯åŠ¨å¤±è´¥ï¼š{message}")

        async def terminate(self):
            await self._stop_scheduler()

        def _load_runtime_config(self) -> dict | None:
            config = _build_config_from_astrbot(self.plugin_config)
            if self._test_mode:
                _apply_test_overrides(config)
            return config

        async def _start_scheduler(
            self, run_immediately: bool | None = None
        ) -> tuple[bool, str]:
            if self._scheduler_task and not self._scheduler_task.done():
                return False, "Scheduler already running."

            config = self._load_runtime_config()
            if not config:
                return False, "Config not found or empty."

            immediate = (
                self._run_immediately if run_immediately is None else run_immediately
            )
            sessions = _build_push_sessions(self.plugin_config)
            if not sessions:
                return False, "No push sessions configured."
            use_pixiv_cat = bool(self.plugin_config.get("use_pixiv_cat", True))

            async def _notifier_factory(_, __, ___, ____):
                return [
                    AstrBotNotifier(
                        context=self.context,
                        sessions=sessions,
                        max_pages=config.get("notifier", {}).get("max_pages", 10),
                        multi_page_mode=config.get("notifier", {}).get(
                            "multi_page_mode", "cover_link"
                        ),
                        use_pixiv_cat=use_pixiv_cat,
                        proxy_url=config.get("network", {}).get("proxy_url"),
                    )
                ]

            task = asyncio.create_task(
                run_scheduler(
                    config,
                    run_immediately=immediate,
                    notifiers_factory=_notifier_factory,
                )
            )
            task.add_done_callback(self._on_scheduler_done)
            self._scheduler_task = task
            return True, "Scheduler started."

        async def _stop_scheduler(self) -> tuple[bool, str]:
            if not self._scheduler_task or self._scheduler_task.done():
                return False, "Scheduler not running."

            self._scheduler_task.cancel()
            try:
                await asyncio.wait_for(self._scheduler_task, timeout=15)
            except asyncio.CancelledError:
                self._scheduler_task = None
            except asyncio.TimeoutError:
                return False, "Scheduler stop timeout."
            except Exception:
                self._scheduler_task = None
                raise
            else:
                self._scheduler_task = None
            return True, "Scheduler stopped."

        def _on_scheduler_done(self, task: asyncio.Task) -> None:
            try:
                task.result()
            except asyncio.CancelledError:
                logger.info("AstrBot: scheduler task cancelled.")
            except Exception as exc:
                self._last_error = str(exc)
                logger.error(f"AstrBot: scheduler crashed: {exc}", exc_info=True)

        async def _run_once_background(self) -> tuple[bool, str]:
            config = self._load_runtime_config()
            if not config:
                return False, "Config not found or empty."

            sessions = _build_push_sessions(self.plugin_config)
            if not sessions:
                return False, "No push sessions configured."
            use_pixiv_cat = bool(self.plugin_config.get("use_pixiv_cat", True))

            async def _notifier_factory(_, __, ___, ____):
                return [
                    AstrBotNotifier(
                        context=self.context,
                        sessions=sessions,
                        max_pages=config.get("notifier", {}).get("max_pages", 10),
                        multi_page_mode=config.get("notifier", {}).get(
                            "multi_page_mode", "cover_link"
                        ),
                        use_pixiv_cat=use_pixiv_cat,
                        proxy_url=config.get("network", {}).get("proxy_url"),
                    )
                ]

            async def _run():
                async with self._run_once_lock:
                    await run_once(config, notifiers_factory=_notifier_factory)

            asyncio.create_task(_run())
            return True, "Run-once task started."

        async def _update_profile_background(self) -> tuple[bool, str]:
            config = self._load_runtime_config()
            if not config:
                return False, "Config not found or empty."

            pixiv_cfg = config.get("pixiv", {})
            if not pixiv_cfg.get("user_id"):
                return False, "æœªé…ç½® Pixiv user_idï¼Œæ— æ³•æ›´æ–°ç”¨æˆ·ç”»åƒã€‚"
            if not (pixiv_cfg.get("refresh_token") or pixiv_cfg.get("sync_token")):
                return False, "æœªé…ç½® Pixiv Tokenï¼Œæ— æ³•æ›´æ–°ç”¨æˆ·ç”»åƒã€‚"

            async def _notifier_factory(_, __, ___, ____):
                return []

            async def _run():
                async with self._run_once_lock:
                    main_client = None
                    sync_client = None
                    try:
                        main_client, sync_client, profiler, _ = await setup_services(
                            config, notifiers_factory=_notifier_factory
                        )
                        profiler_cfg = config.get("profiler", {})
                        await profiler.build_profile(
                            user_id=pixiv_cfg.get("user_id"),
                            scan_limit=profiler_cfg.get("scan_limit", 500),
                            include_private=profiler_cfg.get("include_private", True),
                        )
                        top_tags = await profiler.get_top_tags(
                            profiler_cfg.get("top_n", 20)
                        )
                        logger.info(
                            f"âœ… ç”¨æˆ·ç”»åƒæ›´æ–°å®Œæˆï¼ŒTop Tags: {[t[0] for t in top_tags[:10]]}"
                        )
                    except Exception as e:
                        self._last_error = str(e)
                        logger.error(f"æ›´æ–°ç”¨æˆ·ç”»åƒå¤±è´¥ï¼š{e}")
                    finally:
                        if main_client:
                            await main_client.close()
                        if sync_client and sync_client is not main_client:
                            await sync_client.close()

            asyncio.create_task(_run())
            return True, "Profile update task started."

        async def _send_test_push(self) -> tuple[bool, str]:
            config = self._load_runtime_config()
            if not config:
                return False, "æœªæ‰¾åˆ°å¯ç”¨é…ç½®ï¼Œè¯·å…ˆå®Œæˆæ’ä»¶é…ç½®ã€‚"

            sessions = _build_push_sessions(self.plugin_config)
            if not sessions:
                return False, "æœªé…ç½® push_sessionsï¼Œæ— æ³•è¿›è¡Œæµ‹è¯•æ¨é€ã€‚"

            pixiv_cfg = config.get("pixiv", {})
            if not pixiv_cfg.get("refresh_token"):
                return False, "æœªé…ç½® Pixiv refresh_tokenï¼Œæ— æ³•æ‹‰å–æµ‹è¯•ä½œå“ã€‚"

            network_cfg = config.get("network", {})
            client = PixivClient(
                refresh_token=pixiv_cfg.get("refresh_token"),
                requests_per_minute=network_cfg.get("requests_per_minute", 60),
                random_delay=tuple(network_cfg.get("random_delay", [1.0, 3.0])),
                max_concurrency=network_cfg.get("max_concurrency", 5),
                proxy_url=network_cfg.get("proxy_url"),
            )

            use_pixiv_cat = bool(self.plugin_config.get("use_pixiv_cat", True))
            notifier = AstrBotNotifier(
                context=self.context,
                sessions=sessions,
                max_pages=config.get("notifier", {}).get("max_pages", 10),
                multi_page_mode=config.get("notifier", {}).get(
                    "multi_page_mode", "cover_link"
                ),
                use_pixiv_cat=use_pixiv_cat,
                proxy_url=network_cfg.get("proxy_url"),
            )

            try:
                logged_in = await client.login()
                if not logged_in:
                    return False, "Pixiv ç™»å½•å¤±è´¥æˆ–æœªç™»å½•ï¼Œæ— æ³•è·å–æµ‹è¯•ä½œå“ã€‚"

                illusts = await client.get_ranking(limit=1)
                if not illusts:
                    return False, "æœªè·å–åˆ°æµ‹è¯•ä½œå“ï¼Œè¯·ç¨åé‡è¯•ã€‚"

                illust = illusts[0]
                await notifier.push_illusts(
                    [illust], message_prefix="ğŸ§ª PixivXP æµ‹è¯•æ¨é€"
                )
                return True, f"âœ… å·²å‘é€æµ‹è¯•ä½œå“ï¼š{illust.title} (#{illust.id})"
            except Exception as e:
                logger.error(f"æµ‹è¯•æ¨é€å¤±è´¥ï¼š{e}")
                return False, f"âŒ æµ‹è¯•æ¨é€å¤±è´¥ï¼š{e}"
            finally:
                await notifier.close()
                await client.close()

        @filter.command_group("pixivxp", alias={"pixiv", "xp"})
        def pixivxp(self):
            """Pixiv-XP-Pusher control group."""
            pass

        @pixivxp.command("status")
        async def status(self, event: AstrMessageEvent):
            running = bool(self._scheduler_task and not self._scheduler_task.done())
            config = self._load_runtime_config() or {}
            cron = config.get("scheduler", {}).get("cron", "N/A")
            sessions = _build_push_sessions(self.plugin_config)
            status = "è¿è¡Œä¸­" if running else "å·²åœæ­¢"
            msg = (
                "ğŸ“Š PixivXP çŠ¶æ€\n"
                f"è°ƒåº¦ï¼š{status}\n"
                f"å®šæ—¶ï¼š{cron}\n"
                f"æ¨é€ä¼šè¯ï¼š{len(sessions)}\n"
                f"è‡ªåŠ¨å¯åŠ¨ï¼š{'æ˜¯' if self._auto_start else 'å¦'}\n"
                f"ç«‹å³æ‰§è¡Œï¼š{'æ˜¯' if self._run_immediately else 'å¦'}\n"
                f"æµ‹è¯•æ¨¡å¼ï¼š{'æ˜¯' if self._test_mode else 'å¦'}"
            )
            if self._last_error:
                msg += f"\næœ€è¿‘é”™è¯¯ï¼š{self._last_error}"
            yield event.plain_result(msg)

        @filter.permission_type(filter.PermissionType.ADMIN)
        @pixivxp.command("start")
        async def start(self, event: AstrMessageEvent):
            started, message = await self._start_scheduler()
            if not started:
                yield event.plain_result(f"âŒ å¯åŠ¨å¤±è´¥ï¼š{message}")
                return
            config = self._load_runtime_config() or {}
            cron = config.get("scheduler", {}).get("cron", "N/A")
            sessions = _build_push_sessions(self.plugin_config)
            yield event.plain_result(
                "âœ… å®šæ—¶ä»»åŠ¡å·²å¯åŠ¨\n"
                f"å®šæ—¶ï¼š{cron}\n"
                f"æ¨é€ä¼šè¯ï¼š{len(sessions)}\n"
                f"ç«‹å³æ‰§è¡Œï¼š{'æ˜¯' if self._run_immediately else 'å¦'}"
            )

        @filter.permission_type(filter.PermissionType.ADMIN)
        @pixivxp.command("stop")
        async def stop(self, event: AstrMessageEvent):
            stopped, message = await self._stop_scheduler()
            if not stopped:
                yield event.plain_result(f"âŒ åœæ­¢å¤±è´¥ï¼š{message}")
                return
            yield event.plain_result("ğŸ›‘ å®šæ—¶ä»»åŠ¡å·²åœæ­¢ã€‚")

        @filter.permission_type(filter.PermissionType.ADMIN)
        @pixivxp.command("once")
        async def once(self, event: AstrMessageEvent):
            ok, message = await self._run_once_background()
            if not ok:
                yield event.plain_result(f"âŒ ä¸€æ¬¡æ€§æ¨é€å¯åŠ¨å¤±è´¥ï¼š{message}")
                return
            yield event.plain_result(
                "ğŸš€ å·²è§¦å‘ä¸€æ¬¡æ€§æ¨é€ä»»åŠ¡\næç¤ºï¼šä»»åŠ¡åœ¨åå°æ‰§è¡Œï¼Œå¯æŸ¥çœ‹æ—¥å¿—ç¡®è®¤è¿›åº¦ã€‚"
            )

        @filter.permission_type(filter.PermissionType.ADMIN)
        @pixivxp.command("test")
        async def test(self, event: AstrMessageEvent):
            ok, message = await self._send_test_push()
            yield event.plain_result(message)

        @filter.permission_type(filter.PermissionType.ADMIN)
        @pixivxp.command("reload")
        async def reload(self, event: AstrMessageEvent):
            await self._stop_scheduler()
            started, message = await self._start_scheduler()
            if not started:
                yield event.plain_result(f"âŒ é‡è½½å¤±è´¥ï¼š{message}")
                return
            yield event.plain_result("ğŸ”„ é…ç½®å·²é‡è½½ï¼Œå®šæ—¶ä»»åŠ¡å·²é‡æ–°å¯åŠ¨ã€‚")

        @filter.permission_type(filter.PermissionType.ADMIN)
        @pixivxp.command("profile")
        async def profile(self, event: AstrMessageEvent):
            ok, message = await self._update_profile_background()
            if not ok:
                yield event.plain_result(f"âŒ æ›´æ–°ç”¨æˆ·ç”»åƒå¤±è´¥ï¼š{message}")
                return
            yield event.plain_result(
                "ğŸ§  å·²è§¦å‘ç”¨æˆ·ç”»åƒæ›´æ–°\næç¤ºï¼šä»»åŠ¡åœ¨åå°æ‰§è¡Œï¼Œå¯æŸ¥çœ‹æ—¥å¿—ç¡®è®¤è¿›åº¦ã€‚"
            )

        @pixivxp.command("search")
        async def search(self, event: AstrMessageEvent, query: GreedyStr):
            """Pixiv æœç´¢

            ç”¨æ³•ï¼š/pixivxp search <query>
            """
            raw_query = str(query).strip() if query is not None else ""
            if not raw_query or raw_query.lower() == "greedystr":
                yield event.plain_result("ç”¨æ³•ï¼š/pixivxp search <query>")
                return

            config = self._load_runtime_config()
            if not config:
                yield event.plain_result("é…ç½®ç¼ºå¤±ï¼Œæ— æ³•æ‰§è¡Œæœç´¢ã€‚")
                return

            pixiv_cfg = config.get("pixiv", {})
            token = pixiv_cfg.get("refresh_token") or pixiv_cfg.get("sync_token")
            if not token:
                yield event.plain_result("æœªé…ç½® Pixiv Tokenï¼Œæ— æ³•æ‰§è¡Œæœç´¢ã€‚")
                return

            network_cfg = config.get("network", {})
            fetcher_cfg = config.get("fetcher", {})
            filter_cfg = config.get("filter", {})
            search_limit = int(fetcher_cfg.get("search_limit", 50))
            return_count = max(1, min(10, search_limit))
            bookmark_threshold = fetcher_cfg.get("bookmark_threshold", {}).get(
                "search", 0
            )
            date_range_days = int(fetcher_cfg.get("date_range_days", 7))
            r18_mode = filter_cfg.get("r18_mode", "mixed")
            exclude_ai = bool(filter_cfg.get("exclude_ai", True))
            use_pixiv_cat = bool(self.plugin_config.get("use_pixiv_cat", True))
            max_pages = int(config.get("notifier", {}).get("max_pages", 10))

            client = PixivClient(
                refresh_token=token,
                requests_per_minute=network_cfg.get("requests_per_minute", 60),
                random_delay=tuple(network_cfg.get("random_delay", [1.0, 3.0])),
                max_concurrency=network_cfg.get("max_concurrency", 5),
                proxy_url=network_cfg.get("proxy_url"),
            )
            try:
                logged_in = await client.login()
                if not logged_in:
                    yield event.plain_result("Pixiv ç™»å½•å¤±è´¥æˆ–æœªç™»å½•ï¼Œæ— æ³•æœç´¢ã€‚")
                    return

                tag_result = _parse_search_tags(raw_query)
                if not tag_result["success"]:
                    yield event.plain_result(tag_result["error_message"])
                    return

                include_tags = tag_result["include_tags"]
                exclude_tags = tag_result["exclude_tags"]

                illusts = await client.search_illusts(
                    tags=include_tags,
                    bookmark_threshold=bookmark_threshold,
                    date_range_days=date_range_days,
                    limit=search_limit,
                    search_target="partial_match_for_tags",
                )
                if not illusts and date_range_days > 0:
                    illusts = await client.search_illusts(
                        tags=include_tags,
                        bookmark_threshold=bookmark_threshold,
                        date_range_days=0,
                        limit=search_limit,
                        search_target="title_and_caption",
                    )
                if not illusts:
                    yield event.plain_result("æœªæ‰¾åˆ°ç›¸å…³æ’ç”»ã€‚")
                    return

                filtered, filter_messages = _filter_search_illusts(
                    illusts, exclude_tags, r18_mode, exclude_ai
                )
                for msg in filter_messages:
                    yield event.plain_result(msg)
                if not filtered:
                    return

                to_send = _sample_illusts(filtered, return_count)
                proxy_url = network_cfg.get("proxy_url")
                async with aiohttp.ClientSession() as session:
                    for illust in to_send:
                        url = _pick_search_image_url(
                            illust, use_pixiv_cat=use_pixiv_cat, max_pages=max_pages
                        )
                        if not url:
                            yield event.plain_result(
                                f"è·³è¿‡æ— å¯å‘é€å›¾ç‰‡çš„ä½œå“ï¼š#{illust.id}"
                            )
                            continue
                        try:
                            img_data = await download_image_with_referer(
                                session, url, proxy=proxy_url
                            )
                            if img_data:
                                yield event.chain_result(
                                    [Image.fromBytes(img_data), Plain(_format_search_message(illust))]
                                )
                            else:
                                yield event.plain_result(
                                    f"å›¾ç‰‡ä¸‹è½½å¤±è´¥ï¼Œä»…å‘é€ä¿¡æ¯ï¼š\n{_format_search_message(illust)}"
                                )
                        except Exception as e:
                            logger.warning(f"æœç´¢å›¾ç‰‡å‘é€å¤±è´¥ï¼š{e}")
                            yield event.plain_result(
                                f"å›¾ç‰‡ä¸‹è½½å¤±è´¥ï¼Œä»…å‘é€ä¿¡æ¯ï¼š\n{_format_search_message(illust)}"
                            )
            except Exception as e:
                logger.error(f"æœç´¢å¤±è´¥ï¼š{e}")
                yield event.plain_result(f"âŒ æœç´¢å¤±è´¥ï¼š{e}")
            finally:
                await client.close()

        @filter.event_message_type(filter.EventMessageType.ALL)
        async def on_matrix_reaction(self, event: AstrMessageEvent):
            if event.get_platform_name() != "matrix":
                return

            raw = getattr(event.message_obj, "raw_message", None)
            if not raw or getattr(raw, "msgtype", "") != "m.reaction":
                return

            if str(event.get_sender_id()) == str(event.get_self_id()):
                return

            relates_to = getattr(raw, "content", {}).get("m.relates_to", {}) or {}
            target_event_id = relates_to.get("event_id")
            if not target_event_id:
                return

            client = getattr(event, "client", None)
            if not client:
                return

            room_id = event.get_session_id()
            try:
                target_event = await client.get_event(room_id, target_event_id)
            except Exception as e:
                logger.debug(f"æ‹‰å– Matrix ç›®æ ‡äº‹ä»¶å¤±è´¥ï¼š{e}")
                return

            if not isinstance(target_event, dict):
                return

            if str(target_event.get("sender")) != str(event.get_self_id()):
                return

            illust_id = await self._resolve_pixiv_illust_id_from_matrix_event(
                client, room_id, target_event
            )
            if not illust_id:
                return

            ok = await self._add_pixiv_bookmark_from_reaction(illust_id)
            if ok:
                logger.info(f"å·²é€šè¿‡ Matrix ååº”æ·»åŠ æ”¶è—ï¼š{illust_id}")
            else:
                logger.warning(f"Matrix ååº”æ·»åŠ æ”¶è—å¤±è´¥ï¼š{illust_id}")
