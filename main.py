from __future__ import annotations

import asyncio
import os
import sys
from pathlib import Path
from typing import TYPE_CHECKING

from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger

# Ensure project root in path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

import aiohttp
from database import cache_illust, init_db, mark_pushed
from fetcher import ContentFetcher
from filter import ContentFilter
from pixiv_client import PixivClient
from profiler import XPProfiler
from utils import download_image_with_referer, get_pixiv_cat_url

from astrbot.api import logger
from astrbot.core.utils.io import save_temp_img

try:
    from astrbot.api import AstrBotConfig
    from astrbot.api.event import AstrMessageEvent, MessageChain, filter
    from astrbot.api.star import Context, Star
except Exception:  # pragma: no cover - allow standalone CLI usage
    AstrBotConfig = None
    AstrMessageEvent = None
    MessageChain = None
    Context = None
    Star = None
    filter = None

if TYPE_CHECKING:
    from pixiv_client import Illust


async def retry_async(
    coro_func,
    *args,
    max_retries: int = 3,
    delay: float = 5.0,
    backoff: float = 2.0,
    **kwargs,
):
    """
    é€šç”¨å¼‚æ­¥é‡è¯•å‡½æ•°

    Args:
        coro_func: è¦æ‰§è¡Œçš„å¼‚æ­¥å‡½æ•°
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        delay: åˆå§‹å»¶è¿Ÿç§’æ•°
        backoff: å»¶è¿Ÿå€å¢ç³»æ•°

    Returns:
        å‡½æ•°è¿”å›å€¼ï¼Œæˆ–åœ¨æ‰€æœ‰é‡è¯•å¤±è´¥åè¿”å› None
    """
    current_delay = delay

    for attempt in range(max_retries + 1):
        try:
            return await coro_func(*args, **kwargs)
        except Exception as e:
            if attempt < max_retries:
                logger.warning(
                    f"æ“ä½œå¤±è´¥ (å°è¯• {attempt + 1}/{max_retries + 1}): {e}ï¼Œ{current_delay:.1f}s åé‡è¯•..."
                )
                await asyncio.sleep(current_delay)
                current_delay *= backoff
            else:
                logger.error(f"æ“ä½œæœ€ç»ˆå¤±è´¥ (å·²é‡è¯• {max_retries} æ¬¡): {e}")

    return None


# å…¨å±€è¿è¡Œé”ï¼Œé˜²æ­¢ä»»åŠ¡å¹¶å‘
_task_lock = asyncio.Lock()


async def setup_notifiers(
    config: dict,
    client: PixivClient,
    profiler: XPProfiler,
    sync_client: PixivClient = None,
):
    raise RuntimeError(
        "Non-AstrBot notifiers have been removed; use notifiers_factory."
    )


async def setup_services(config: dict, notifiers_factory=None):
    """åˆå§‹åŒ–å…¨å±€æœåŠ¡ (DB, Client, Profiler, Notifiers)"""
    await init_db()

    # å…¬å…±ç½‘ç»œé…ç½®
    network_cfg = config.get("network", {})
    pixiv_cfg = config.get("pixiv", {})
    proxy_url = network_cfg.get("proxy_url")

    client_kwargs = {
        "requests_per_minute": network_cfg.get("requests_per_minute", 60),
        "random_delay": tuple(network_cfg.get("random_delay", [1.0, 3.0])),
        "max_concurrency": network_cfg.get("max_concurrency", 5),
        "proxy_url": proxy_url,
    }

    # ä¸»å®¢æˆ·ç«¯ (ç”¨äºæœç´¢ã€æ’è¡Œæ¦œç­‰é«˜é£é™©æ“ä½œ)
    main_client = PixivClient(
        refresh_token=pixiv_cfg.get("refresh_token"), **client_kwargs
    )
    await main_client.login()

    # åŒæ­¥å®¢æˆ·ç«¯ (ç”¨äºè·å–æ”¶è—ã€å…³æ³¨åŠ¨æ€ç­‰ä½é£é™©æ“ä½œ)
    sync_token = pixiv_cfg.get("sync_token")
    if sync_token:
        sync_client = PixivClient(refresh_token=sync_token, **client_kwargs)
        await sync_client.login()
        logger.info("âœ… å·²å¯ç”¨åŒæ­¥ä¸“ç”¨ Token (sync_token)")
    else:
        sync_client = main_client  # å›é€€åˆ°ä¸»å®¢æˆ·ç«¯
        logger.info("æœªé…ç½® sync_tokenï¼Œæ”¶è—åŒæ­¥å°†ä½¿ç”¨ä¸» Token")

    # Init Profiler (ä½¿ç”¨ sync_clientï¼Œåªè¯»æ“ä½œ)
    profiler_cfg = config.get("profiler", {})
    profiler = XPProfiler(
        client=sync_client,  # ä½¿ç”¨åŒæ­¥å®¢æˆ·ç«¯è·å–æ”¶è—
        stop_words=profiler_cfg.get("stop_words"),
        discovery_rate=profiler_cfg.get("discovery_rate", 0.1),
        time_decay_days=profiler_cfg.get("time_decay_days", 180),
        ai_config=profiler_cfg.get("ai"),
        saturation_threshold=profiler_cfg.get("saturation_threshold", 0.5),
        ai_provider=config.get("_astrbot_chat_provider"),
    )

    # Init Notifiers (ä½¿ç”¨ main_client ç”¨äºä¸‹è½½å›¾ç‰‡ç­‰ï¼Œsync_client ç”¨äº on_action å›è°ƒ)
    if notifiers_factory:
        notifiers = await notifiers_factory(config, main_client, profiler, sync_client)
    else:
        notifiers = await setup_notifiers(config, main_client, profiler, sync_client)

    # è¿”å›åŒå®¢æˆ·ç«¯
    return main_client, sync_client, profiler, notifiers


async def main_task(
    config: dict,
    client: PixivClient,
    profiler: XPProfiler,
    notifiers: list,
    sync_client: PixivClient = None,
):
    """
    æ‰§è¡Œä¸€æ¬¡å®Œæ•´çš„æ¨é€ä»»åŠ¡ (ä¾èµ–å¤–éƒ¨æœåŠ¡)

    Args:
        client: ä¸»å®¢æˆ·ç«¯ (ç”¨äºæœç´¢ã€æ’è¡Œæ¦œã€ä¸‹è½½)
        sync_client: åŒæ­¥å®¢æˆ·ç«¯ (ç”¨äºè·å–å…³æ³¨åŠ¨æ€ï¼Œå¯é€‰)
    """
    # å¦‚æœæœªä¼ å…¥ sync_clientï¼Œä½¿ç”¨ main_client
    if sync_client is None:
        sync_client = client

    if _task_lock.locked():
        logger.info("â³ æ¨é€ä»»åŠ¡æ­£åœ¨è¿è¡Œä¸­ï¼Œæœ¬æ¬¡è§¦å‘å·²è·³è¿‡æˆ–æ’é˜Ÿ")

    async with _task_lock:
        logger.info("=== å¼€å§‹æ¨é€ä»»åŠ¡ ===")

    try:
        # 1. æ„å»º/æ›´æ–° XP ç”»åƒ
        profiler_cfg = config.get("profiler", {})

        await profiler.build_profile(
            user_id=config["pixiv"]["user_id"],
            scan_limit=profiler_cfg.get("scan_limit", 500),
            include_private=profiler_cfg.get("include_private", True),
        )

        top_tags = await profiler.get_top_tags(profiler_cfg.get("top_n", 20))
        logger.info(f"Top XP Tags: {[t[0] for t in top_tags[:10]]}")

        if config.get(
            "test"
        ):  # Test mode skip heavy DB load if possible, but we need it for xp_profile
            pass

        # è·å–å®Œæ•´çš„ XP Profile ç”¨äºåŒ¹é…åº¦è®¡ç®—
        import database as db_module

        xp_profile = await db_module.get_xp_profile()

        # 2. è·å–å†…å®¹
        fetcher_cfg = config.get("fetcher", {})

        # 1.5 è·å–å…³æ³¨åˆ—è¡¨ï¼ˆä½¿ç”¨ sync_clientï¼Œä½é£é™©æ“ä½œï¼‰
        following_ids = set()
        pixiv_uid = config.get("pixiv", {}).get("user_id", 0)
        if pixiv_uid:
            try:
                following_ids = await sync_client.fetch_following(user_id=pixiv_uid)
            except Exception as e:
                logger.warning(f"è·å–å…³æ³¨åˆ—è¡¨å¤±è´¥ï¼š{e}")

        manual_subs = set(fetcher_cfg.get("subscribed_artists") or [])
        all_subs = list(following_ids | manual_subs)
        logger.info(
            f"æœ‰æ•ˆå…³æ³¨ç”»å¸ˆæ•°ï¼š{len(all_subs)} (API è·å–ï¼š{len(following_ids)}, æ‰‹åŠ¨ï¼š{len(manual_subs)})"
        )

        # ContentFetcher: æœç´¢/æ’è¡Œæ¦œç”¨ clientï¼Œè®¢é˜…æ£€æŸ¥ç”¨ sync_client
        fetcher = ContentFetcher(
            client=client,
            sync_client=sync_client,  # æ–°å¢ï¼šåŒæ­¥å®¢æˆ·ç«¯
            bookmark_threshold=fetcher_cfg.get(
                "bookmark_threshold", {"search": 1000, "subscription": 0}
            ),
            date_range_days=fetcher_cfg.get("date_range_days", 7),
            subscribed_artists=list(manual_subs),
            discovery_rate=profiler_cfg.get("discovery_rate", 0.1),
            ranking_config=fetcher_cfg.get("ranking"),
            dynamic_threshold_config=fetcher_cfg.get(
                "dynamic_threshold"
            ),  # åŠ¨æ€é˜ˆå€¼é…ç½®
            search_limit=fetcher_cfg.get("search_limit", 50),  # æœç´¢æ•°é‡é™åˆ¶ (é»˜è®¤ 50)
        )

        # æ‰§è¡Œ Discovery (Search + Ranking + Subs)
        top_tags = await profiler.get_top_tags(
            profiler_cfg.get("top_n", 20)
        )  # Re-get is cheap

        # æ‰§è¡Œ Discovery (Search + Ranking + Subs) -> MAB Scheduled
        top_tags = await profiler.get_top_tags(
            profiler_cfg.get("top_n", 20)
        )  # Re-get is cheap

        all_illusts = await fetcher.fetch_content(
            xp_tags=top_tags, total_limit=fetcher_cfg.get("discovery_limit", 200)
        )
        logger.info(f"å…±è·å– {len(all_illusts)} ä¸ªå€™é€‰ä½œå“")

        # 3. è¿‡æ»¤
        filter_cfg = config.get("filter", {})
        match_cfg = fetcher_cfg.get("match_score", {})

        astrbot_chat_provider = config.get("_astrbot_chat_provider")
        astrbot_embedding_provider = config.get("_astrbot_embedding_provider")

        # åˆå§‹åŒ–å¯é€‰çš„ Embedder (AI è¯­ä¹‰åŒ¹é…)
        embedder = None
        ai_cfg = config.get("ai", {})
        embedding_cfg = ai_cfg.get("embedding", {})
        if embedding_cfg.get("enabled", False):
            try:
                from embedder import Embedder

                embedder = Embedder(
                    embedding_cfg, embedding_provider=astrbot_embedding_provider
                )
                if embedder.enabled:
                    logger.info(f"å·²å¯ç”¨ AI è¯­ä¹‰åŒ¹é… (model={embedder.model})")
            except Exception as e:
                logger.warning(f"Embedder åˆå§‹åŒ–å¤±è´¥ï¼š{e}")

        # åˆå§‹åŒ–å¯é€‰çš„ AIScorer (LLM ç²¾æ’)
        ai_scorer = None
        scorer_cfg = ai_cfg.get("scorer", {})
        if scorer_cfg.get("enabled", False):
            try:
                from ai_scorer import AIScorer

                # æ”¯æŒå¤ç”¨ profiler.ai çš„ API é…ç½®
                if scorer_cfg.get("use_profiler_api", True):
                    profiler_ai_cfg = config.get("profiler", {}).get("ai", {})
                    # åˆå¹¶é…ç½®ï¼šscorer ä¼˜å…ˆï¼Œç¼ºå¤±çš„ä» profiler.ai ç»§æ‰¿
                    merged_cfg = {
                        "enabled": scorer_cfg.get("enabled", False),
                        "provider": scorer_cfg.get("provider")
                        or profiler_ai_cfg.get("provider", "openai"),
                        "api_key": scorer_cfg.get("api_key")
                        or profiler_ai_cfg.get("api_key", ""),
                        "base_url": scorer_cfg.get("base_url")
                        or profiler_ai_cfg.get("base_url", ""),
                        "model": scorer_cfg.get("model")
                        or profiler_ai_cfg.get("model", "gpt-4o-mini"),
                        "max_candidates": scorer_cfg.get("max_candidates", 50),
                        "score_weight": scorer_cfg.get("score_weight", 0.3),
                    }
                    ai_scorer = AIScorer(merged_cfg, provider=astrbot_chat_provider)
                else:
                    ai_scorer = AIScorer(scorer_cfg, provider=astrbot_chat_provider)

                if ai_scorer.enabled:
                    logger.info(f"å·²å¯ç”¨ AI ç²¾æ’è¯„åˆ† (model={ai_scorer.model})")
            except Exception as e:
                logger.warning(f"AIScorer åˆå§‹åŒ–å¤±è´¥ï¼š{e}")

        content_filter = ContentFilter(
            blacklist_tags=filter_cfg.get("blacklist_tags"),
            daily_limit=filter_cfg.get("daily_limit", 20),
            exclude_ai=filter_cfg.get("exclude_ai", True),
            min_match_score=match_cfg.get("min_threshold", 0.0),
            match_weight=match_cfg.get("weight_in_sort", 0.5),
            max_per_artist=filter_cfg.get("max_per_artist", 3),
            subscribed_artists=all_subs,
            artist_boost=filter_cfg.get("artist_boost", 0.3),
            min_create_days=filter_cfg.get("min_create_days", 0),
            r18_mode=filter_cfg.get("r18_mode", False),
            # æ–°å¢ï¼šå€Ÿé‰´ X ç®—æ³•çš„å¢å¼ºé€‰é¡¹
            author_diversity=filter_cfg.get("author_diversity"),
            source_boost=filter_cfg.get("source_boost"),
            embedder=embedder,  # å¯é€‰çš„è¯­ä¹‰åŒ¹é…
            ai_scorer=ai_scorer,  # å¯é€‰çš„ LLM ç²¾æ’
            # å¤šæ ·æ€§å¢å¼º
            shuffle_factor=filter_cfg.get("shuffle_factor", 0.0),
            exploration_ratio=filter_cfg.get("exploration_ratio", 0.0),
        )

        pixiv_uid = config.get("pixiv", {}).get("user_id", 0)
        filtered = await content_filter.filter(
            all_illusts, xp_profile=xp_profile, user_id=pixiv_uid
        )
        logger.info(f"è¿‡æ»¤å {len(filtered)} ä¸ªä½œå“")

        # 4. æ¨é€
        if notifiers and filtered:
            try:
                # ç¼“å­˜ä½œå“ä¿¡æ¯ (åŒ…å«æ¥æºå½’å› )
                for illust in filtered:
                    await cache_illust(
                        illust.id,
                        illust.tags,
                        illust.user_id,
                        illust.user_name,
                        source=illust.source,
                    )

                all_sent_ids = set()
                for notifier in notifiers:
                    try:
                        sent_ids = await notifier.send(filtered)
                        all_sent_ids.update(sent_ids)
                    except Exception as e:
                        logger.error(f"æ¨é€å™¨ {type(notifier).__name__} å‘é€å¤±è´¥ï¼š{e}")

                if all_sent_ids:
                    # è®°å½•æ¨é€å†å²
                    filtered_map = {ill.id: ill for ill in filtered}
                    for pid in all_sent_ids:
                        if pid in filtered_map:
                            illust = filtered_map[pid]
                            source = getattr(illust, "source", "unknown")
                            await mark_pushed(pid, source)

                            # æ›´æ–° MAB ç­–ç•¥ç»Ÿè®¡ (Total Count)
                            if source in [
                                "xp_search",
                                "subscription",
                                "ranking",
                                "related",
                                "engagement_artists",
                            ]:
                                await db_module.update_strategy_stats(
                                    source, is_success=False
                                )

                    # å°†æ¶ˆæ¯ ID å†™å…¥æ•°æ®åº“ç¼“å­˜ï¼ˆç”¨äºè¿é”æ¨é€å¼•ç”¨ï¼‰
                    for notifier in notifiers:
                        if hasattr(notifier, "_message_illust_map"):
                            for (
                                msg_id,
                                illust_id,
                            ) in notifier._message_illust_map.items():
                                if illust_id in all_sent_ids:
                                    await db_module.set_chain_meta(
                                        illust_id, chain_depth=0, chain_msg_id=msg_id
                                    )

                    logger.info(
                        f"æ¨é€å®Œæˆï¼š{len(all_sent_ids)}/{len(filtered)} ä¸ªä½œå“æˆåŠŸ"
                    )
                else:
                    logger.error("æ²¡æœ‰ä»»ä½•ä½œå“è¢«æˆåŠŸæ¨é€")

                # 5. AI é”™è¯¯æŠ¥è­¦
                ai_errors = profiler.ai_processor.occurred_errors
                if ai_errors:
                    err_count = len(ai_errors)
                    err_id = ai_errors[0]
                    msg = f"âš ï¸ è­¦å‘Šï¼šæœ¬æ¬¡ä»»åŠ¡æœ‰ {err_count} æ‰¹ Tag AI ä¼˜åŒ–å¤±è´¥ã€‚\nå·²è‡ªåŠ¨è®°å½•å¹¶é™çº§å¤„ç†ã€‚"
                    buttons = [("ğŸ”„ é‡è¯•ä¿®å¤", f"retry_ai:{err_id}")]
                    logger.warning(f"AI ä¼˜åŒ–å¤±è´¥ {err_count} æ¬¡ï¼Œå‘é€è­¦å‘Š")

                    for notifier in notifiers:
                        if hasattr(notifier, "send_text"):
                            try:
                                await notifier.send_text(msg, buttons)
                            except Exception as e:
                                logger.debug(f"AI é”™è¯¯æç¤ºå‘é€å¤±è´¥ï¼š{e}")
            except Exception as e:
                logger.error(f"æ¨é€è¿‡ç¨‹å‡ºé”™ï¼š{e}")
        elif not filtered:
            logger.info("æ— æ–°ä½œå“å¯æ¨é€")
        else:
            logger.warning("æœªé…ç½®æ¨é€å™¨")

    except Exception as e:
        logger.error(f"ä»»åŠ¡æ‰§è¡Œå‡ºé”™ï¼š{e}", exc_info=True)

    logger.info("=== æ¨é€ä»»åŠ¡ç»“æŸ ===")


async def run_once(config: dict, notifiers_factory=None):
    """ç«‹å³æ‰§è¡Œä¸€æ¬¡"""
    main_client, sync_client, profiler, notifiers = await setup_services(
        config, notifiers_factory=notifiers_factory
    )

    # Run-once æ˜¯ Fire-and-Forget è¡Œä¸º

    try:
        await main_task(config, main_client, profiler, notifiers, sync_client)
    finally:
        await main_client.close()
        # å¦‚æœ sync_client æ˜¯ç‹¬ç«‹å®ä¾‹ï¼Œä¹Ÿéœ€è¦å…³é—­
        if sync_client is not main_client:
            await sync_client.close()
        for n in notifiers or []:
            if hasattr(n, "close"):
                try:
                    await n.close()
                except Exception as e:
                    logger.debug(f"å…³é—­æ¨é€å™¨å¤±è´¥ï¼š{e}")


async def daily_report_task(config: dict, notifiers: list, profiler=None):
    """æ¯æ—¥ç»´æŠ¤ä»»åŠ¡ï¼šç”Ÿæˆæ—¥æŠ¥ + æ•°æ®æ¸…ç† + AI æ ‡ç­¾åˆ·æ–°

    è®¾è®¡åŸåˆ™ï¼š
    - æ¯ä¸ªæ­¥éª¤ç‹¬ç«‹ try/exceptï¼Œå³ä½¿æŸä¸€æ­¥å¤±è´¥ï¼Œå…¶ä»–æ­¥éª¤ä»å¯ç»§ç»­
    - ç½‘ç»œç›¸å…³æ“ä½œï¼ˆAIã€å‘é€ï¼‰ä½¿ç”¨ retry_async è‡ªåŠ¨é‡è¯•
    """
    logger.info("ğŸ“Š å¼€å§‹æ‰§è¡Œæ¯æ—¥ç»´æŠ¤ä»»åŠ¡...")

    maintenance_summary = []
    lines = ["ğŸ“Š **æ¯æ—¥ XP æ—¥æŠ¥**\n"]

    # ========== 1. ç”Ÿæˆæ—¥æŠ¥ (Top Tags + MAB Stats) ==========
    try:
        from database import get_all_strategy_stats, get_top_xp_tags

        top_tags = await get_top_xp_tags(10)
        stats = await get_all_strategy_stats()

        if top_tags:
            lines.append("ğŸ¯ **Top 10 XP æ ‡ç­¾**")
            for i, (tag, weight) in enumerate(top_tags[:10], 1):
                lines.append(f"  {i}. `{tag}` ({weight:.1f})")
            lines.append("")

        if stats:
            lines.append("ğŸ“ˆ **MAB ç­–ç•¥è¡¨ç°**")
            strategy_names = {
                "search": "XP æœç´¢",
                "xp_search": "XP æœç´¢",
                "subscription": "è®¢é˜…",
                "ranking": "æ’è¡Œæ¦œ",
            }
            for strategy, data in stats.items():
                name = strategy_names.get(strategy, strategy)
                rate_pct = data["rate"] * 100
                lines.append(
                    f"  â€¢ {name}: {data['success']}/{data['total']} ({rate_pct:.1f}%)"
                )
    except Exception as e:
        logger.error(f"ç”Ÿæˆæ—¥æŠ¥ç»Ÿè®¡å¤±è´¥ï¼š{e}")
        maintenance_summary.append(f"âš ï¸ æ—¥æŠ¥ç»Ÿè®¡å¤±è´¥ï¼š{e}")

    # ========== 2. åŒæ­¥å±è”½æ ‡ç­¾åˆ° XP ç”»åƒ ==========
    try:
        from database import sync_blocked_tags_to_xp

        blocked_removed = await sync_blocked_tags_to_xp()
        if blocked_removed > 0:
            maintenance_summary.append(
                f"ğŸš« ä»ç”»åƒä¸­ç§»é™¤ {blocked_removed} ä¸ªå·²å±è”½æ ‡ç­¾"
            )
            logger.info(f"å·²ä» XP ç”»åƒä¸­ç§»é™¤ {blocked_removed} ä¸ªå±è”½æ ‡ç­¾")
    except Exception as e:
        logger.error(f"åŒæ­¥å±è”½æ ‡ç­¾å¤±è´¥ï¼š{e}")
        maintenance_summary.append(f"âš ï¸ åŒæ­¥å±è”½æ ‡ç­¾å¤±è´¥ï¼š{e}")

    # ========== 3. AI æ ‡ç­¾å¢é‡å¤„ç† (å¸¦é‡è¯•) ==========
    if profiler and hasattr(profiler, "ai_processor") and profiler.ai_processor.enabled:
        try:
            from database import get_uncached_tags

            uncached_tags = await get_uncached_tags(limit=200)
            if uncached_tags:
                logger.info(f"å‘ç° {len(uncached_tags)} ä¸ªæœªå¤„ç†æ ‡ç­¾ï¼Œå¯åŠ¨ AI æ¸…æ´—...")

                async def _ai_process():
                    return await profiler.ai_processor.process_tags(uncached_tags)

                result = await retry_async(_ai_process, max_retries=3, delay=10.0)
                if result:
                    valid_tags, mapping = result
                    maintenance_summary.append(
                        f"ğŸ¤– AI æ¸…æ´— {len(uncached_tags)} ä¸ªæ ‡ç­¾ â†’ {len(valid_tags)} ä¸ªæœ‰æ•ˆ"
                    )
                    logger.info(
                        f"AI æ¸…æ´—å®Œæˆï¼š{len(valid_tags)}/{len(uncached_tags)} æœ‰æ•ˆ"
                    )
                else:
                    maintenance_summary.append("âš ï¸ AI æ¸…æ´—å¤±è´¥ (å·²é‡è¯•)")
        except Exception as e:
            logger.error(f"AI æ¸…æ´—å¤±è´¥ï¼š{e}")
            maintenance_summary.append(f"âš ï¸ AI æ¸…æ´—å¤±è´¥ï¼š{e}")

    # ========== 4. æ¸…ç†æ—§æ¨é€å†å² ==========
    try:
        from database import cleanup_old_sent_history

        old_removed = await cleanup_old_sent_history(days=30)
        if old_removed > 0:
            maintenance_summary.append(f"ğŸ—‘ï¸ æ¸…ç† {old_removed} æ¡è¿‡æœŸæ¨é€è®°å½•")
            logger.info(f"å·²æ¸…ç† {old_removed} æ¡ 30 å¤©å‰çš„æ¨é€å†å²")
    except Exception as e:
        logger.error(f"æ¸…ç†æ¨é€å†å²å¤±è´¥ï¼š{e}")
        maintenance_summary.append(f"âš ï¸ æ¸…ç†æ¨é€å†å²å¤±è´¥ï¼š{e}")

    # ========== 5. æ¸…ç†æ—§ä½œå“ç¼“å­˜ ==========
    try:
        from database import cleanup_old_illust_cache

        cache_removed = await cleanup_old_illust_cache(days=60)
        if cache_removed > 0:
            maintenance_summary.append(f"ğŸ—‘ï¸ æ¸…ç† {cache_removed} æ¡è¿‡æœŸä½œå“ç¼“å­˜")
            logger.info(f"å·²æ¸…ç† {cache_removed} æ¡ 60 å¤©å‰çš„ä½œå“ç¼“å­˜")
    except Exception as e:
        logger.error(f"æ¸…ç†ä½œå“ç¼“å­˜å¤±è´¥ï¼š{e}")
        maintenance_summary.append(f"âš ï¸ æ¸…ç†ä½œå“ç¼“å­˜å¤±è´¥ï¼š{e}")

    # ========== 6. æ·»åŠ ç»´æŠ¤æ‘˜è¦åˆ°æ—¥æŠ¥ ==========
    if maintenance_summary:
        lines.append("")
        lines.append("ğŸ› ï¸ **ç»´æŠ¤è®°å½•**")
        for item in maintenance_summary:
            lines.append(f"  {item}")

    report_msg = "\n".join(lines)

    # ========== 7. å‘é€æ—¥æŠ¥ (å¸¦é‡è¯•) ==========
    async def _send_report():
        for n in notifiers:
            if hasattr(n, "send_text"):
                await n.send_text(report_msg)
                return True
        return False

    result = await retry_async(_send_report, max_retries=5, delay=30.0, backoff=2.0)
    if not result:
        logger.error("å‘é€æ—¥æŠ¥æœ€ç»ˆå¤±è´¥")

    logger.info("âœ… æ¯æ—¥ç»´æŠ¤ä»»åŠ¡å®Œæˆ")


async def run_scheduler(
    config: dict, run_immediately: bool = False, notifiers_factory=None
):
    """å¯åŠ¨è°ƒåº¦å™¨ (Daemon Mode)"""
    main_client, sync_client, profiler, notifiers = await setup_services(
        config, notifiers_factory=notifiers_factory
    )

    if run_immediately:
        logger.info("ğŸš€ æ­£åœ¨ç«‹å³æ‰§è¡Œé¦–æ¬¡ä»»åŠ¡...")
        asyncio.create_task(
            main_task(config, main_client, profiler, notifiers, sync_client)
        )

    scheduler = AsyncIOScheduler()
    scheduler_cfg = config.get("scheduler", {})
    coalesce = scheduler_cfg.get("coalesce", True)

    # è·å–è°ƒåº¦é…ç½® (ä¼˜å…ˆè¯»å–æ•°æ®åº“)
    from database import get_state

    db_cron = await get_state("schedule_cron")
    config_cron = config.get("scheduler", {}).get("cron", "0 20 * * *")

    schedule_str = db_cron if db_cron else config_cron

    # å°† scheduler æ³¨å…¥åˆ° config ä¸­ä»¥ä¾¿ callback è®¿é—®
    config["scheduler"] = scheduler

    # æ”¯æŒå¤šä¸ªæ—¶é—´ç‚¹
    # é€»è¾‘ä¼˜åŒ–ï¼š
    # 1. å…ˆå°è¯•å°†æ•´ä¸ªå­—ç¬¦ä¸²ä½œä¸ºä¸€ä¸ª Cronï¼Œå¦‚æœæˆåŠŸåˆ™è®¤ä¸ºæ˜¯ä¸€ä¸ªä»»åŠ¡ (è§£å†³ "0 12,21 * * *" è¢«è¯¯æ‹†çš„é—®é¢˜)
    # 2. å¦‚æœå¤±è´¥ï¼Œå†å°è¯•ç”¨é€—å·åˆ†å‰² (å…¼å®¹æ—§çš„å¤šä»»åŠ¡å†™æ³• "0 12 * * *, 0 21 * * *")

    cron_list = []

    # å°è¯•è§£ææ•´ä½“
    try:
        CronTrigger.from_crontab(schedule_str.strip())
        cron_list = [schedule_str.strip()]
        logger.info(f"è¯†åˆ«ä¸ºå•ä¸€å®šæ—¶ä»»åŠ¡ï¼š{schedule_str}")
    except ValueError:
        # æ•´ä½“è§£æå¤±è´¥ï¼Œå°è¯•åˆ†å‰²
        potential_crons = [c.strip() for c in schedule_str.split(",") if c.strip()]
        valid_crons = []
        for c in potential_crons:
            try:
                CronTrigger.from_crontab(c)
                valid_crons.append(c)
            except ValueError:
                logger.warning(f"å¿½ç•¥æ— æ•ˆçš„ Cron è¡¨è¾¾å¼ç‰‡æ®µï¼š{c}")

        if valid_crons:
            cron_list = valid_crons
            logger.info(f"è¯†åˆ«ä¸º {len(cron_list)} ä¸ªç‹¬ç«‹å®šæ—¶ä»»åŠ¡")
        else:
            # å¦‚æœåˆ†å‰²ä¹Ÿå…¨é”™ï¼Œé‚£å¯èƒ½å°±æ˜¯æ•´ä½“å†™é”™äº†ï¼Œä¿ç•™æ•´ä½“è®©åé¢æŠ¥é”™
            cron_list = [schedule_str]

    for i, cron_expr in enumerate(cron_list):
        try:
            scheduler.add_job(
                main_task,
                CronTrigger.from_crontab(cron_expr),
                args=[config, main_client, profiler, notifiers, sync_client],
                id=f"push_job_{i}",
                coalesce=coalesce,
                misfire_grace_time=3600,
            )
            logger.info(f"å·²æ·»åŠ å®šæ—¶ä»»åŠ¡ #{i + 1}: {cron_expr}")
        except Exception as e:
            logger.error(f"æ·»åŠ å®šæ—¶ä»»åŠ¡å¤±è´¥ ({cron_expr}): {e}")

    # æ¯æ—¥ç»´æŠ¤ä»»åŠ¡ (æ—¥æŠ¥ + æ¸…ç†)
    daily_cron = scheduler_cfg.get("daily_report_cron", "0 0 * * *")  # é»˜è®¤æ¯å¤© 00:00
    try:
        scheduler.add_job(
            daily_report_task,
            CronTrigger.from_crontab(daily_cron),
            args=[config, notifiers, profiler],  # ä¼ å…¥ profiler ä»¥æ”¯æŒ AI æ¸…æ´—
            id="daily_report_job",
            coalesce=True,
            misfire_grace_time=3600,
        )
        logger.info(f"å·²æ·»åŠ æ¯æ—¥ç»´æŠ¤ä»»åŠ¡ï¼š{daily_cron}")
    except Exception as e:
        logger.error(f"æ·»åŠ æ¯æ—¥ç»´æŠ¤ä»»åŠ¡å¤±è´¥ï¼š{e}")

    scheduler.start()
    logger.info(f"è°ƒåº¦å™¨å·²å¯åŠ¨ï¼Œå…± {len(cron_list)} ä¸ªæ¨é€ä»»åŠ¡ + 1 ä¸ªæ¯æ—¥ç»´æŠ¤ä»»åŠ¡")

    try:
        stop_event = asyncio.Event()
        await stop_event.wait()
    except (KeyboardInterrupt, SystemExit, asyncio.CancelledError):
        scheduler.shutdown()
        raise
    finally:
        await main_client.close()
        # å¦‚æœ sync_client æ˜¯ç‹¬ç«‹å®ä¾‹ï¼Œä¹Ÿéœ€è¦å…³é—­
        if sync_client is not main_client:
            await sync_client.close()
        for n in notifiers or []:
            if hasattr(n, "close"):
                try:
                    await n.close()
                except Exception as e:
                    logger.debug(f"å…³é—­æ¨é€å™¨å¤±è´¥ï¼š{e}")


def _apply_test_overrides(config: dict) -> None:
    config.setdefault("profiler", {})["scan_limit"] = 10
    config["profiler"]["discovery_rate"] = 0
    config.setdefault("fetcher", {})["bookmark_threshold"] = {
        "search": 0,
        "subscription": 0,
    }
    config.setdefault("fetcher", {})["discovery_limit"] = 1
    config["fetcher"]["ranking"] = {"modes": ["day"], "limit": 1}
    config["test"] = True


def _get_list(cfg: dict, key: str, default: list):
    value = cfg.get(key, default)
    if value is None:
        return list(default)
    if isinstance(value, list):
        return value
    return [value]


def _build_config_from_astrbot(plugin_cfg: "AstrBotConfig") -> dict:
    """Build Pixiv-XP-Pusher config from AstrBot plugin config."""
    pixiv_cfg = plugin_cfg.get("pixiv", {}) or {}
    profiler_cfg = plugin_cfg.get("profiler", {}) or {}
    profiler_ai_cfg = profiler_cfg.get("ai", {}) or {}
    ai_cfg = plugin_cfg.get("ai", {}) or {}
    scheduler_cfg = plugin_cfg.get("scheduler", {}) or {}
    filter_cfg = plugin_cfg.get("filter", {}) or {}
    fetcher_cfg = plugin_cfg.get("fetcher", {}) or {}
    network_cfg = plugin_cfg.get("network", {}) or {}

    config = {
        "pixiv": {
            "user_id": pixiv_cfg.get("user_id", 0),
            "refresh_token": pixiv_cfg.get("refresh_token", ""),
            "sync_token": pixiv_cfg.get("sync_token", ""),
        },
        "strategies": _get_list(
            plugin_cfg,
            "strategies",
            ["xp_search", "related", "ranking", "subscription"],
        ),
        "profiler": {
            "ai": {
                "enabled": profiler_ai_cfg.get("enabled", False),
                "provider": profiler_ai_cfg.get("provider", "openai"),
                "api_key": profiler_ai_cfg.get("api_key", ""),
                "base_url": profiler_ai_cfg.get("base_url", ""),
                "model": profiler_ai_cfg.get("model", "gpt-4o-mini"),
                "concurrency": profiler_ai_cfg.get("concurrency", 10),
                "batch_size": profiler_ai_cfg.get("batch_size", 200),
                "filter_meaningless": profiler_ai_cfg.get("filter_meaningless", True),
                "merge_synonyms": profiler_ai_cfg.get("merge_synonyms", True),
            },
            "scan_limit": profiler_cfg.get("scan_limit", 1000),
            "discovery_rate": profiler_cfg.get("discovery_rate", 0.1),
            "time_decay_days": profiler_cfg.get("time_decay_days", 180),
            "saturation_threshold": profiler_cfg.get("saturation_threshold", 0.5),
            "top_n": profiler_cfg.get("top_n", 20),
            "include_private": profiler_cfg.get("include_private", True),
            "stop_words": _get_list(
                profiler_cfg,
                "stop_words",
                ["original", "manga", "pixiv", "illustration"],
            ),
        },
        "ai": {
            "embedding": ai_cfg.get("embedding", {}),
            "scorer": ai_cfg.get("scorer", {}),
        },
        "scheduler": {
            "cron": scheduler_cfg.get("cron", "0 12 * * *"),
            "coalesce": scheduler_cfg.get("coalesce", True),
            "daily_report_cron": scheduler_cfg.get("daily_report_cron", "0 0 * * *"),
        },
        "filter": {
            "match_score": {
                "min_threshold": filter_cfg.get("min_match_score", 0.0),
                "weight_in_sort": filter_cfg.get("match_weight", 0.6),
            },
            "daily_limit": filter_cfg.get("daily_limit", 20),
            "exclude_ai": filter_cfg.get("exclude_ai", True),
            "max_per_artist": filter_cfg.get("max_per_artist", 3),
            "artist_boost": filter_cfg.get("artist_boost", 0.3),
            "min_create_days": filter_cfg.get("min_create_days", 0),
            "r18_mode": filter_cfg.get("r18_mode", "mixed"),
            "shuffle_factor": filter_cfg.get("shuffle_factor", 0.0),
            "exploration_ratio": filter_cfg.get("exploration_ratio", 0.0),
            "blacklist_tags": _get_list(filter_cfg, "blacklist_tags", []),
            "author_diversity": filter_cfg.get("author_diversity", {}),
            "source_boost": filter_cfg.get("source_boost", {}),
        },
        "fetcher": {
            "bookmark_threshold": {
                "search": fetcher_cfg.get("bookmark_threshold", {}).get("search", 1000),
                "subscription": fetcher_cfg.get("bookmark_threshold", {}).get(
                    "subscription", 0
                ),
            },
            "subscribed_artists": _get_list(fetcher_cfg, "subscribed_artists", []),
            "date_range_days": fetcher_cfg.get("date_range_days", 7),
            "dynamic_threshold": fetcher_cfg.get("dynamic_threshold", {}),
            "search_limit": fetcher_cfg.get("search_limit", 50),
            "ranking": fetcher_cfg.get(
                "ranking",
                {"enabled": True, "modes": ["day", "week", "month"], "limit": 100},
            ),
            "match_score": fetcher_cfg.get("match_score", {}),
            "mab_limits": fetcher_cfg.get(
                "mab_limits", {"min_quota": 0.2, "max_quota": 0.6}
            ),
        },
        "network": {
            "requests_per_minute": network_cfg.get("requests_per_minute", 60),
            "random_delay": network_cfg.get("random_delay", [1.0, 3.0]),
            "max_concurrency": network_cfg.get("max_concurrency", 5),
            "proxy_url": network_cfg.get("proxy_url", ""),
        },
        "astrbot": {
            "use_astrbot_providers": plugin_cfg.get("use_astrbot_providers", False),
            "chat_provider_id": plugin_cfg.get("chat_provider_id", ""),
            "embedding_provider_id": plugin_cfg.get("embedding_provider_id", ""),
        },
        "notifier": {
            "max_pages": plugin_cfg.get("max_pages", 10),
            "multi_page_mode": plugin_cfg.get("multi_page_mode", "cover_link"),
        },
    }

    return config


def _build_push_sessions(plugin_cfg: "AstrBotConfig") -> list[str]:
    return _get_list(plugin_cfg, "push_sessions", [])


class AstrBotNotifier:
    """Send Pixiv messages through AstrBot's builtin proactive channels."""

    def __init__(
        self,
        context: "Context",
        sessions: list[str],
        max_pages: int = 10,
        multi_page_mode: str = "cover_link",
        use_pixiv_cat: bool = True,
        proxy_url: str | None = None,
    ) -> None:
        self.context = context
        self.sessions = sessions
        self.max_pages = max_pages
        self.multi_page_mode = multi_page_mode
        self.use_pixiv_cat = use_pixiv_cat
        self.proxy_url = proxy_url
        self._session: aiohttp.ClientSession | None = None

    def _pick_image_urls(self, illust: "Illust") -> list[str]:
        if not illust.page_count:
            return []
        limit = max(1, min(self.max_pages, illust.page_count))
        if self.use_pixiv_cat:
            return [get_pixiv_cat_url(illust.id, i) for i in range(limit)]
        if illust.image_urls:
            return illust.image_urls[:limit]
        return []

    async def _get_session(self) -> aiohttp.ClientSession:
        if self._session is None or self._session.closed:
            self._session = aiohttp.ClientSession()
        return self._session

    async def _download_to_file(self, url: str) -> str | None:
        try:
            session = await self._get_session()
            data = await download_image_with_referer(
                session, url, proxy=self.proxy_url
            )
            return save_temp_img(data)
        except Exception as e:
            logger.warning(f"ä¸‹è½½å›¾ç‰‡å¤±è´¥ï¼š{e}")
            return None

    def format_message(self, illust: "Illust") -> str:
        tags = ", ".join(illust.tags[:20]) if illust.tags else "N/A"
        r18 = "R18" if illust.is_r18 else "SAFE"
        return (
            f"ğŸ¨ {illust.title} (#{illust.id})\n"
            f"ğŸ‘¤ {illust.user_name} ({illust.user_id})\n"
            f"ğŸ”– {tags}\n"
            f"â­ {illust.bookmark_count} | ğŸ‘€ {illust.view_count} | {r18}\n"
            f"ğŸ”— https://www.pixiv.net/artworks/{illust.id}"
        )

    def handle_feedback(self, illust_id: int, action: str) -> bool:
        return False

    async def _send_chain(self, chain: "MessageChain") -> None:
        for session in self.sessions:
            await self.context.send_message(session, chain)

    async def send(self, illusts: list["Illust"]) -> list[int]:
        if not illusts or not self.sessions:
            return []

        success_ids = []
        for illust in illusts:
            chain = MessageChain()
            chain.message(self.format_message(illust))

            image_urls = self._pick_image_urls(illust)
            if image_urls:
                urls = (
                    image_urls
                    if self.multi_page_mode == "multi_image"
                    else [image_urls[0]]
                )
                for url in urls:
                    path = await self._download_to_file(url)
                    if path:
                        chain.file_image(path)
                    else:
                        chain.url_image(url)

            await self._send_chain(chain)
            success_ids.append(illust.id)
        return success_ids

    async def send_text(
        self, text: str, buttons: list[tuple[str, str]] | None = None
    ) -> bool:
        if not self.sessions:
            return False
        chain = MessageChain()
        chain.message(text)
        await self._send_chain(chain)
        return True

    async def push_illusts(
        self,
        illusts: list["Illust"],
        message_prefix: str = "",
        reply_to_message_id: int | None = None,
    ) -> dict[int, int | None]:
        sent_map: dict[int, int | None] = {}
        if not illusts:
            return sent_map
        for illust in illusts:
            chain = MessageChain()
            if message_prefix:
                chain.message(f"{message_prefix}\n")
            chain.message(self.format_message(illust))

            image_urls = self._pick_image_urls(illust)
            if image_urls:
                path = await self._download_to_file(image_urls[0])
                if path:
                    chain.file_image(path)
                else:
                    chain.url_image(image_urls[0])
            await self._send_chain(chain)
            sent_map[illust.id] = None
        return sent_map

    async def close(self) -> None:
        if self._session and not self._session.closed:
            await self._session.close()


if Star is not None:

    class PixivXPPusherPlugin(Star):
        """Pixiv XP Pusher plugin wrapper for AstrBot."""

        def __init__(self, context: Context, config: AstrBotConfig) -> None:
            super().__init__(context)
            self.context = context
            self.plugin_config = config
            self.plugin_dir = Path(__file__).parent
            self._scheduler_task: asyncio.Task | None = None
            self._run_once_lock = asyncio.Lock()
            self._last_error: str | None = None

            self._auto_start = bool(self.plugin_config.get("auto_start", True))
            self._run_immediately = bool(
                self.plugin_config.get("run_immediately", False)
            )
            self._test_mode = bool(self.plugin_config.get("test_mode", False))
            self._use_pixiv_cat = bool(self.plugin_config.get("use_pixiv_cat", True))

        async def initialize(self):
            if self._auto_start:
                started, message = await self._start_scheduler()
                if not started:
                    logger.error(f"AstrBot: è‡ªåŠ¨å¯åŠ¨å¤±è´¥ï¼š{message}")

        async def terminate(self):
            await self._stop_scheduler()

        def _load_runtime_config(self) -> dict | None:
            config = _build_config_from_astrbot(self.plugin_config)
            astrbot_cfg = config.get("astrbot", {})
            if astrbot_cfg.get("use_astrbot_providers"):
                chat_provider_id = astrbot_cfg.get("chat_provider_id") or ""
                embedding_provider_id = astrbot_cfg.get("embedding_provider_id") or ""

                chat_provider = None
                if chat_provider_id:
                    chat_provider = self.context.get_provider_by_id(chat_provider_id)
                    if not chat_provider:
                        # å…è®¸ç”¨â€œæä¾›å•†æº ID/æ˜¾ç¤ºåâ€å‰ç¼€åŒ¹é…
                        candidates = [
                            p
                            for p in self.context.get_all_providers()
                            if p.meta().id.startswith(f"{chat_provider_id}/")
                        ]
                        if len(candidates) == 1:
                            chat_provider = candidates[0]
                            logger.info(
                                f"AstrBot: å·²å°† LLM Provider ID è§£æä¸º {chat_provider.meta().id}"
                            )
                        elif candidates:
                            logger.warning(
                                f"AstrBot: LLM Provider ID '{chat_provider_id}' åŒ¹é…åˆ°å¤šä¸ªå€™é€‰ï¼š"
                                + ", ".join(p.meta().id for p in candidates)
                            )
                        else:
                            logger.warning(
                                f"AstrBot: æœªæ‰¾åˆ° LLM Provider ID: {chat_provider_id}"
                            )
                    elif not hasattr(chat_provider, "text_chat"):
                        logger.warning(
                            f"AstrBot: Provider ID {chat_provider_id} ä¸æ˜¯å¯ç”¨çš„ LLM Provider"
                        )
                        chat_provider = None
                else:
                    try:
                        chat_provider = self.context.get_using_provider()
                    except Exception as exc:
                        logger.warning(f"AstrBot: è·å–é»˜è®¤ LLM Provider å¤±è´¥ï¼š{exc}")

                embedding_provider = None
                if embedding_provider_id:
                    embedding_provider = self.context.get_provider_by_id(
                        embedding_provider_id
                    )
                    if not embedding_provider:
                        candidates = [
                            p
                            for p in self.context.get_all_embedding_providers()
                            if p.meta().id.startswith(f"{embedding_provider_id}/")
                        ]
                        if len(candidates) == 1:
                            embedding_provider = candidates[0]
                            logger.info(
                                "AstrBot: å·²å°† Embedding Provider ID è§£æä¸º "
                                f"{embedding_provider.meta().id}"
                            )
                        elif candidates:
                            logger.warning(
                                f"AstrBot: Embedding Provider ID '{embedding_provider_id}' åŒ¹é…åˆ°å¤šä¸ªå€™é€‰ï¼š"
                                + ", ".join(p.meta().id for p in candidates)
                            )
                        else:
                            logger.warning(
                                f"AstrBot: æœªæ‰¾åˆ° Embedding Provider ID: {embedding_provider_id}"
                            )
                    elif not hasattr(embedding_provider, "get_embedding"):
                        logger.warning(
                            f"AstrBot: Provider ID {embedding_provider_id} ä¸æ˜¯å¯ç”¨çš„ Embedding Provider"
                        )
                        embedding_provider = None
                else:
                    providers = self.context.get_all_embedding_providers()
                    if providers:
                        embedding_provider = providers[0]
                    else:
                        logger.warning("AstrBot: æœªé…ç½® Embedding Provider")

                config["_astrbot_chat_provider"] = chat_provider
                config["_astrbot_embedding_provider"] = embedding_provider
            if self._test_mode:
                _apply_test_overrides(config)
            return config

        async def _start_scheduler(
            self, run_immediately: bool | None = None
        ) -> tuple[bool, str]:
            if self._scheduler_task and not self._scheduler_task.done():
                return False, "Scheduler already running."

            config = self._load_runtime_config()
            if not config:
                return False, "Config not found or empty."

            immediate = (
                self._run_immediately if run_immediately is None else run_immediately
            )
            sessions = _build_push_sessions(self.plugin_config)
            if not sessions:
                return False, "No push sessions configured."

            async def _notifier_factory(_, __, ___, ____):
                return [
                    AstrBotNotifier(
                        context=self.context,
                        sessions=sessions,
                        max_pages=config.get("notifier", {}).get("max_pages", 10),
                        multi_page_mode=config.get("notifier", {}).get(
                            "multi_page_mode", "cover_link"
                        ),
                        use_pixiv_cat=self._use_pixiv_cat,
                        proxy_url=config.get("network", {}).get("proxy_url"),
                    )
                ]

            task = asyncio.create_task(
                run_scheduler(
                    config,
                    run_immediately=immediate,
                    notifiers_factory=_notifier_factory,
                )
            )
            task.add_done_callback(self._on_scheduler_done)
            self._scheduler_task = task
            return True, "Scheduler started."

        async def _stop_scheduler(self) -> tuple[bool, str]:
            if not self._scheduler_task or self._scheduler_task.done():
                return False, "Scheduler not running."

            self._scheduler_task.cancel()
            try:
                await asyncio.wait_for(self._scheduler_task, timeout=15)
            except asyncio.CancelledError:
                self._scheduler_task = None
            except asyncio.TimeoutError:
                return False, "Scheduler stop timeout."
            except Exception:
                self._scheduler_task = None
                raise
            else:
                self._scheduler_task = None
            return True, "Scheduler stopped."

        def _on_scheduler_done(self, task: asyncio.Task) -> None:
            try:
                task.result()
            except asyncio.CancelledError:
                logger.info("AstrBot: scheduler task cancelled.")
            except Exception as exc:
                self._last_error = str(exc)
                logger.error(f"AstrBot: scheduler crashed: {exc}", exc_info=True)

        async def _run_once_background(self) -> tuple[bool, str]:
            config = self._load_runtime_config()
            if not config:
                return False, "Config not found or empty."

            sessions = _build_push_sessions(self.plugin_config)
            if not sessions:
                return False, "No push sessions configured."

            async def _notifier_factory(_, __, ___, ____):
                return [
                    AstrBotNotifier(
                        context=self.context,
                        sessions=sessions,
                        max_pages=config.get("notifier", {}).get("max_pages", 10),
                        multi_page_mode=config.get("notifier", {}).get(
                            "multi_page_mode", "cover_link"
                        ),
                        use_pixiv_cat=self._use_pixiv_cat,
                    )
                ]

            async def _run():
                async with self._run_once_lock:
                    await run_once(config, notifiers_factory=_notifier_factory)

            asyncio.create_task(_run())
            return True, "Run-once task started."

        @filter.command_group("pixivxp", alias={"pixiv", "xp"})
        def pixivxp(self):
            """Pixiv-XP-Pusher control group."""
            pass

        @pixivxp.command("status")
        async def status(self, event: AstrMessageEvent):
            running = bool(self._scheduler_task and not self._scheduler_task.done())
            last_error = f" Last error: {self._last_error}" if self._last_error else ""
            yield event.plain_result(
                f"Pixiv-XP-Pusher status: {'running' if running else 'stopped'}.{last_error}"
            )

        @filter.permission_type(filter.PermissionType.ADMIN)
        @pixivxp.command("start")
        async def start(self, event: AstrMessageEvent):
            started, message = await self._start_scheduler()
            yield event.plain_result(message)

        @filter.permission_type(filter.PermissionType.ADMIN)
        @pixivxp.command("stop")
        async def stop(self, event: AstrMessageEvent):
            stopped, message = await self._stop_scheduler()
            yield event.plain_result(message)

        @filter.permission_type(filter.PermissionType.ADMIN)
        @pixivxp.command("once")
        async def once(self, event: AstrMessageEvent):
            ok, message = await self._run_once_background()
            yield event.plain_result(message if ok else f"Run-once failed: {message}")

        @filter.permission_type(filter.PermissionType.ADMIN)
        @pixivxp.command("reload")
        async def reload(self, event: AstrMessageEvent):
            await self._stop_scheduler()
            started, message = await self._start_scheduler()
            yield event.plain_result(message)
